{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerBarrey/An-lisis-cuantitativo-avanzados/blob/main/Ejercicio_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 4\n",
        "\n",
        "\n",
        "Se utiliza un modelo de Churn de usuarios de tarjetas de crédito:\n",
        "https://www.kaggle.com/code/mzmdgaming/credit-card-customer-churn-model"
      ],
      "metadata": {
        "id": "RxXbMhbmpiaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar la base"
      ],
      "metadata": {
        "id": "tmvL5l0vhaSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\n",
        "    'username': userdata.get('KAGGLE_USER'),\n",
        "    'key': userdata.get('KAGGLE_KEY')}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d thedevastator/predicting-credit-card-customer-attrition-with-m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvJWAhHBhb_O",
        "outputId": "cfbf79ad-6d79-43c3-816f-ba2f3e72245f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/thedevastator/predicting-credit-card-customer-attrition-with-m\n",
            "License(s): CC0-1.0\n",
            "Downloading predicting-credit-card-customer-attrition-with-m.zip to /content\n",
            "  0% 0.00/379k [00:00<?, ?B/s]\n",
            "100% 379k/379k [00:00<00:00, 76.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraigo todos los archivos que están en el .zip que acabamos de \"bajar\".\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()"
      ],
      "metadata": {
        "id": "n4TgflhJmGSk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/BankChurners.csv')"
      ],
      "metadata": {
        "id": "pVQU4sycmJT9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preguntas"
      ],
      "metadata": {
        "id": "a3tQcSNKmUia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta 1: ¿Cuántos de los usuarios son attrited?\n",
        "\n",
        "Ayuda: La variable que identifica a estos usuarios es 'Attrition_Flag'\n",
        "\n",
        "Una función posible para calcularlo es: .value_counts()"
      ],
      "metadata": {
        "id": "yzR8_TTynvyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Attrition_Flag'].value_counts()"
      ],
      "metadata": {
        "id": "N46W8M-5mWTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "10b3fb08-9068-48d4-965a-54189b4dbe4c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Attrition_Flag\n",
              "Existing Customer    8500\n",
              "Attrited Customer    1627\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attrition_Flag</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Existing Customer</th>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attrited Customer</th>\n",
              "      <td>1627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta 2:\n",
        "\n",
        "El siguiente código genera una variable dummy con valor 0 para los usuarios que permanecen y valor 1 para los que se fueron.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "df['attrited']=pd.get_dummies(df['Attrition_Flag'])['Attrited Customer']\n",
        "```\n",
        "\n",
        "Este otro genera dos datasets distintos, el primero con la información, el segundo con el objetivo\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "variables=['Customer_Age', 'Months_on_book',\n",
        "       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
        "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
        "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt']\n",
        "\n",
        "X=df[variables]\n",
        "Y=df['attrited']\n",
        "```\n",
        "\n",
        "Con esto ya podríamos correr un sencillo modelo LASSO:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=1)\n",
        "lr = LogisticRegression(penalty='l1', max_iter=1000, solver='liblinear')\n",
        "lr.fit(X_train,y_train)\n",
        "```\n",
        "\n",
        "¿Cuál es el score de train y cuál el de test?\n",
        "\n",
        "Ayuda:\n",
        "\n",
        "```\n",
        "print(lr.score(X_train,y_train))\n",
        "print(lr.score(X_test,y_test))\n",
        "```\n",
        "\n",
        "\n",
        "Ok, eso fue fácil, pero ¿Qué significan esos números?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\n"
      ],
      "metadata": {
        "id": "TE00S1MPoDBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#El siguiente código genera una variable dummy con valor 0 para los usuarios que permanecen y valor 1 para los que se fueron.\n",
        "df['attrited']=pd.get_dummies(df['Attrition_Flag'])['Attrited Customer']"
      ],
      "metadata": {
        "id": "nhSBov5tiQiG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Este otro genera dos datasets distintos, el primero con la información, el segundo con el objetivo\n",
        "variables=['Customer_Age', 'Months_on_book',\n",
        "        'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
        "        'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
        "        'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt']\n",
        "\n",
        "X=df[variables]\n",
        "Y=df['attrited']"
      ],
      "metadata": {
        "id": "Ajt6V93qM4L1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Con esto ya podríamos correr un sencillo modelo LASSO:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=1)\n",
        "lr = LogisticRegression(penalty='l1', max_iter=1000, solver='liblinear')\n",
        "lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "BXRNFUqsM3yI",
        "outputId": "76a73465-c4ba-4a10-9efc-b2e331585580"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Score de train y  de test\n",
        "print(lr.score(X_train,y_train))\n",
        "print(lr.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chLdq16_ObIv",
        "outputId": "1f75cbe3-3477-4808-e75c-9b7144d99f35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8738427354647574\n",
            "0.8780848963474828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta 3: Utilice ahora un modelo tipo elastic-net. ¿Mejora la predicción?\n",
        "\n",
        "Ayuda:\n",
        "\n",
        "penalty='elasticnet' y tendrá que cambiar el solver y agregar el l1_ratio"
      ],
      "metadata": {
        "id": "vjOPigduxCZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "penalty='elasticnet'\n",
        "solver='saga'\n",
        "l1_ratio=0.5"
      ],
      "metadata": {
        "id": "seApVFXhxTdp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Utilizando un  modelo tipo elastic-net para obtener el resultado de la nueva prediccion\n",
        "\n",
        "# Elastic-net model\n",
        "enet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "enet.fit(X_train, y_train)\n",
        "\n",
        "# Score de train y de test para el modelo Elastic-net\n",
        "print(enet.score(X_train, y_train))\n",
        "print(enet.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLrO6JV0bPD4",
        "outputId": "7f3bb1b7-0df8-49f8-84de-1fce8156cef0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13732524446042693\n",
            "0.1571874413217098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta 3**: La prediccion empeora usando elasticNet. Según lo que pude investigar una de las razones seria la siguiente: El modelo ElasticNet no está siendo ajustado. Por defecto en scikit-learn, el parámetro l1_ratio de ElasticNet, la mezcla de penalización L1 y L2, está ajustado a 0.5. Un l1_ratio de 0.5 representa una mezcla uniforme de penalización L1 y L2 y no se ajusta a los datos muy bien. La mejor práctica es una búsqueda de cuadrícula de validación cruzada para el valor óptimo de l1_ratio. Ajustar los hiperparámetros del modelo para obtener mejores resultadosseria una opcion por ejemplo l1_ratio pasarlo a 0.3. Como se ve en el ejemplo a continuación los resultados aumentan"
      ],
      "metadata": {
        "id": "ZYh15P5Aa0qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando un  modelo tipo elastic-net para obtener el resultado de la nueva prediccion\n",
        "\n",
        "# Elastic-net model\n",
        "enet = ElasticNet(alpha=0.1, l1_ratio=0.3)\n",
        "enet.fit(X_train, y_train)\n",
        "\n",
        "# Score de train y de test para el modelo Elastic-net\n",
        "print(enet.score(X_train, y_train))\n",
        "print(enet.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RkUGSyfk2U2",
        "outputId": "7d0efb79-6a41-4d9a-dd51-de3b50576ad7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16122500693166852\n",
            "0.1880169099845299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta 4: ¿Cómo es la matriz de confusión? ¿Qué significa?\n",
        "\n",
        "Ayuda:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred=lr.predict(X_test)\n",
        "y_true=y_test\n",
        "confusion_matrix(y_true, y_pred)\n",
        "```\n",
        "\n",
        "También puede utilizar la funión .ravel() para obtener en orden los TN, FP, FN y TP.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n"
      ],
      "metadata": {
        "id": "Pp931Wr3ylUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred=lr.predict(X_test)\n",
        "y_true=y_test\n",
        "confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "gCbxtqBNyspx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9acc9248-d278-4608-f310-030a04f2ec67"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1661,   34],\n",
              "       [ 213,  118]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta 4:**Esta matriz de confusión muestra que el modelo tiene 1662 verdaderos negativos, 33 falsos positivos, 212 falsos negativos y 119 verdaderos positivos.\n",
        "\n",
        "Los verdaderos negativos son las instancias que el modelo predijo correctamente como negativas. Los falsos positivos son las instancias que el modelo predijo incorrectamente como positivas. Los falsos negativos son las instancias que el modelo predijo incorrectamente como negativas. Los verdaderos positivos son las instancias que el modelo predijo correctamente como positivas"
      ],
      "metadata": {
        "id": "Lexw19xkwA-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utilizando la función .ravel() para obtener en orden los TN, FP, FN y TP.**"
      ],
      "metadata": {
        "id": "QgC14p6ivg_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: necesito que utilices la funcion .ravel para obtener los TN, FP, FN Y TP en orden\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = lr.predict (X_test)\n",
        "y_true = y_test\n",
        "confusion_matrix(y_true, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QurrYncPxcPA",
        "outputId": "591866ff-1e6b-4d99-d3e5-dbc1501b108f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TN: 1661, FP: 34, FN: 213, TP: 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta 5: ¿Cómo se puede hacer para obtener una predicción mejor que la obtenida?"
      ],
      "metadata": {
        "id": "NadxqNC70Ncx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Repuesta 5:** Según lo investigado se pueden abordar las siguientes opciones para obtener una prediccion mejor:\n",
        "  1. Ingeniería de características:\n",
        "    - Crear nuevas características a partir de las existentes.\n",
        "    - Transformar las características existentes (por ejemplo, escalar o normalizar).\n",
        "    - Seleccionar las características más relevantes.\n",
        "\n",
        " 2. Selección de modelo:\n",
        "    - Probar diferentes modelos de aprendizaje automático (por ejemplo, árboles de decisión, máquinas de vectores de soporte, redes neuronales).\n",
        "    - Ajustar los hiperparámetros de los modelos para optimizar el rendimiento.\n",
        "\n",
        " 3. Optimización de hiperparámetros:\n",
        "    - Utilizar técnicas de validación cruzada para encontrar los mejores hiperparámetros.\n",
        "    - Buscar los mejores valores para los hiperparámetros utilizando técnicas de optimización (por ejemplo, búsqueda de cuadrícula, optimización bayesiana).\n",
        "\n",
        " 4. Manejo de datos desbalanceados:\n",
        "    - Si los datos están desbalanceados, se pueden utilizar técnicas como oversampling, undersampling o pesos de clase para mejorar el rendimiento del modelo.\n",
        "\n",
        " 5. Validación cruzada:\n",
        "    - Utilizar diferentes técnicas de validación cruzada para evaluar el rendimiento del modelo de forma más robusta.\n",
        "\n",
        " 6. Análisis de errores:\n",
        "    - Analizar los errores del modelo para identificar patrones y mejorar el modelo.\n",
        "\n",
        " 7. Aumento de datos:\n",
        "    - Si los datos son limitados, se pueden utilizar técnicas de aumento de datos para generar más datos de entrenamiento.\n",
        "\n",
        " 8.  Considerar la complejidad del modelo:\n",
        "     -  Evitar el sobreajuste (overfitting) y el subajuste (underfitting) del modelo.\n",
        "     -  Ajustar la complejidad del modelo a los datos disponibles\n"
      ],
      "metadata": {
        "id": "pkXaiR_Bz59N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta 5:** Según lo investigado, de las opciones listadas  la que mas se adapta al modelo que estamos usando es la optimizacion por hiperparámetros. Por que? : Ya que estamos trabajando con un modelo de regresión logística con regularización elastic-net, podemos ajustar el parámetro l1_ratio para encontrar la mejor combinación de penalizaciones L1 y L2.\n",
        "\n",
        "Esto se puede hacer utilizando técnicas de validación cruzada como GridSearchCV : https://scikit-learn.org/stable/modules/grid_search.html#grid-search .\n",
        "\n",
        "Permiten probar diferentes valores de l1_ratio y evaluar el rendimiento del modelo con cada uno, para finalmente seleccionar el que mejor resultados obtenga."
      ],
      "metadata": {
        "id": "gQBDNz7x1Jjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicando e Investigando GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Los datos de C y penalty surgen de la definición del param_grid que se utiliza en GridSearchCV\n",
        "#Param_grid es un diccionario que define los hiperparámetros que se van a optimizar y los valores que se van a probar.\n",
        "#En este caso: C: es el parámetro de regularización inversa. Se prueban los valores 0.1, 1 y 10.\n",
        "#Penalty: es el tipo de norma que se utiliza para la penalización. Se prueban los valores l1 y l2.\n",
        "#GridSearchCV prueba todas las combinaciones posibles de los valores de los hiperparámetros y selecciona la combinación que da el mejor resultado.\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "# create a Logistic Regression model\n",
        "\"\"\"El solver liblinear es una buena opción para conjuntos de datos pequeños o medianos, y es especialmente eficiente para problemas de clasificación binaria como este, donde se predice si un cliente abandonará o no.\n",
        "Además, liblinear es uno de los pocos solvers que admite la regularización L1, que se especifica con penalty='l1'. La regularización L1 es útil para seleccionar características y evitar el sobreajuste, lo que puede ser beneficioso en este caso. \"\"\"\n",
        "lr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "\n",
        "# create a GridSearchCV object\n",
        "\"\"\"\n",
        "El valor de cv=5 en GridSearchCV indica que se está utilizando una validación cruzada de 5 pliegues.Esto significa que el conjunto de datos se divide en 5 partes iguales. El modelo se entrena en 4 partes y se valida en la parte restante. Este proceso se repite 5 veces, utilizando cada parte como conjunto de validación una vez.\n",
        "El resultado final es un promedio de las 5 evaluaciones, lo que da una estimación más robusta del rendimiento del modelo. 5 es un valor comúnmente utilizado para cv, pero se pueden utilizar otros valores dependiendo del tamaño del conjunto de datos y de la complejidad del modelo.\n",
        "\"\"\"\n",
        "grid_search = GridSearchCV(lr, param_grid, cv=5)\n",
        "\n",
        "# fit the GridSearchCV object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Best parameters: \", grid_search.best_params_)#arroja el mejor parametro\n",
        "print(\"Best score: \", grid_search.best_score_) #arroja el mejor score\n",
        "print(\"Test score: \", grid_search.score(X_test, y_test)) #evalua el modelo en el conjunto de testeo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGDRiMhu0mwS",
        "outputId": "b2db4e17-02ac-44ed-c765-4042f5a4ed82"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'C': 1, 'penalty': 'l1'}\n",
            "Best score:  0.8738424688311589\n",
            "Test score:  0.8795656465942744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Investigacion del Resultado**:Estos resultados indican que la mejor combinación de hiperparámetros encontrada por GridSearchCV es C=1 y penalty='l1'. Con estos parámetros, el modelo obtuvo un puntaje promedio de 0.8738 en la validación cruzada.\n",
        "\n",
        "Al evaluar el modelo con estos parámetros en el conjunto de prueba, se obtuvo un puntaje de 0.8796.\n",
        "\n",
        "Comparando con los resultados de la pregunta 2, donde el modelo sin optimización de hiperparámetros tenía un puntaje de test de 0.86, se puede observar una ligera mejora en el rendimiento del modelo.\n",
        "\n",
        "Sin embargo, la mejora es pequeña, lo que podría indicar que los hiperparámetros por defecto del modelo ya eran bastante buenos o que se podría explorar un espacio de búsqueda de hiperparámetros más amplio para obtener una mejora más significativa."
      ],
      "metadata": {
        "id": "TRf9jQ9WClHc"
      }
    }
  ]
}