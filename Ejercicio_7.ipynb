{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerBarrey/An-lisis-cuantitativo-avanzados/blob/main/Ejercicio_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 7\n",
        "\n",
        "## Cargar la base\n",
        "\n",
        "La siguiente base describe datos sobre los salarios, la formación y la experiencia de empleados que realizan entrevistas de trabajo."
      ],
      "metadata": {
        "id": "u3k0JTtjmKkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dGEQ3x7_mx9m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "olHaot2HQL37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe987dae-6959-4bd0-fb45-149e43d0fb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohithsairamreddy/salary-data\n",
            "License(s): Community Data License Agreement - Sharing - Version 1.0\n",
            "Downloading salary-data.zip to /content\n",
            "  0% 0.00/16.6k [00:00<?, ?B/s]\n",
            "100% 16.6k/16.6k [00:00<00:00, 19.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\n",
        "    'username': userdata.get('KAGGLE_USER'),\n",
        "    'key': userdata.get('KAGGLE_KEY')}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d mohithsairamreddy/salary-data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()"
      ],
      "metadata": {
        "id": "rEehM9QyQuqy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cargamos la base\n",
        "df = pd.read_csv('/content/Salary_Data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kGLFhdFVR9iE",
        "outputId": "c2ab86cc-6f76-4dd0-fe91-7508f2856f3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Age  Gender Education Level          Job Title  Years of Experience  \\\n",
              "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
              "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
              "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
              "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
              "4  52.0    Male        Master's           Director                 20.0   \n",
              "\n",
              "     Salary  \n",
              "0   90000.0  \n",
              "1   65000.0  \n",
              "2  150000.0  \n",
              "3   60000.0  \n",
              "4  200000.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4a508cd-0d94-48e1-b852-67db0a13223d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Education Level</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Years of Experience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Bachelor's</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>5.0</td>\n",
              "      <td>90000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>3.0</td>\n",
              "      <td>65000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>PhD</td>\n",
              "      <td>Senior Manager</td>\n",
              "      <td>15.0</td>\n",
              "      <td>150000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Bachelor's</td>\n",
              "      <td>Sales Associate</td>\n",
              "      <td>7.0</td>\n",
              "      <td>60000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>52.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Director</td>\n",
              "      <td>20.0</td>\n",
              "      <td>200000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4a508cd-0d94-48e1-b852-67db0a13223d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4a508cd-0d94-48e1-b852-67db0a13223d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4a508cd-0d94-48e1-b852-67db0a13223d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fa5badc-6a0e-4b7d-b22a-313c42a366be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fa5badc-6a0e-4b7d-b22a-313c42a366be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fa5badc-6a0e-4b7d-b22a-313c42a366be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6704,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.614632626251303,\n        \"min\": 21.0,\n        \"max\": 62.0,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          24.0,\n          27.0,\n          26.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Male\",\n          \"Female\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Bachelor's\",\n          \"Master's\",\n          \"High School\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job Title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"Account Manager\",\n          \"Junior HR Coordinator\",\n          \"Senior Project Manager\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Years of Experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.059003056634102,\n        \"min\": 0.0,\n        \"max\": 34.0,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          9.0,\n          16.0,\n          20.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52786.18391068297,\n        \"min\": 350.0,\n        \"max\": 250000.0,\n        \"num_unique_values\": 444,\n        \"samples\": [\n          101733.0,\n          62807.0,\n          152039.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento de la base\n",
        "\n",
        "Vemos que la variable `Education Level` tiene varios valores similares escritos de manera distinta."
      ],
      "metadata": {
        "id": "BBIUU-NUnMjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Education Level\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "vO8TvDbYStTC",
        "outputId": "f485fbf8-24f0-4020-d67f-070a58f784e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Education Level\n",
              "Bachelor's Degree    2267\n",
              "Master's Degree      1573\n",
              "PhD                  1368\n",
              "Bachelor's            756\n",
              "High School           448\n",
              "Master's              288\n",
              "phD                     1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Education Level</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bachelor's Degree</th>\n",
              "      <td>2267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Master's Degree</th>\n",
              "      <td>1573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PhD</th>\n",
              "      <td>1368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bachelor's</th>\n",
              "      <td>756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High School</th>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Master's</th>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>phD</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para unificar estos valores, la recatogrizamos creando una nueva variable denominada `Education New`:"
      ],
      "metadata": {
        "id": "RKvkvWt8ndGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Education New\"]=df[\"Education Level\"].copy()"
      ],
      "metadata": {
        "id": "skfsZ3tuT3p_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[\"Education Level\"].str.contains(\"Bach\", na=False), \"Education New\"] = \"Bachelor's\"\n",
        "df.loc[df[\"Education Level\"].str.contains(\"Mast\", na=False), \"Education New\"] = \"Master's\"\n",
        "df.loc[df[\"Education Level\"].str.contains(\"hD\", na=False), \"Education New\"] = \"PhD\""
      ],
      "metadata": {
        "id": "jLUsKTFYZK_D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que con estos cambios, las categorías quedaron unificadas"
      ],
      "metadata": {
        "id": "rwziEO4HnpcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Education New\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "C3jD9Z_2noxM",
        "outputId": "8e7e3483-55a6-446a-cca3-df6946cb1b5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Education New\n",
              "Bachelor's     3023\n",
              "Master's       1861\n",
              "PhD            1369\n",
              "High School     448\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Education New</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bachelor's</th>\n",
              "      <td>3023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Master's</th>\n",
              "      <td>1861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PhD</th>\n",
              "      <td>1369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High School</th>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHZ9a9DNpyc5",
        "outputId": "f2f737b3-72d0-44a5-c117-02ced3ec96f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6698 entries, 0 to 6703\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Age                  6698 non-null   float64\n",
            " 1   Gender               6698 non-null   object \n",
            " 2   Education Level      6698 non-null   object \n",
            " 3   Job Title            6698 non-null   object \n",
            " 4   Years of Experience  6698 non-null   float64\n",
            " 5   Salary               6698 non-null   float64\n",
            " 6   Education New        6698 non-null   object \n",
            "dtypes: float64(3), object(4)\n",
            "memory usage: 418.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Borramos además los datos faltantes de la base"
      ],
      "metadata": {
        "id": "gHPxPBZjpcH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "metadata": {
        "id": "L0oQawI6pbmS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que ahora no quedan datos faltantes"
      ],
      "metadata": {
        "id": "ZLTbKpAZp-YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5BLq3pRp-Fx",
        "outputId": "4a88ca1b-a92f-4a78-ebfc-0f0bea35b150"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6698 entries, 0 to 6703\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Age                  6698 non-null   float64\n",
            " 1   Gender               6698 non-null   object \n",
            " 2   Education Level      6698 non-null   object \n",
            " 3   Job Title            6698 non-null   object \n",
            " 4   Years of Experience  6698 non-null   float64\n",
            " 5   Salary               6698 non-null   float64\n",
            " 6   Education New        6698 non-null   object \n",
            "dtypes: float64(3), object(4)\n",
            "memory usage: 418.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preguntas\n",
        "\n",
        "## Pregunta 1\n",
        "\n",
        "Realizar un test de hipótesis para ver si la proporción de mujeres es significativamente menor al 50%.\n",
        "\n",
        "*Ayuda:* el atributo `.shape` devuelve la cantidad de filas y columnas de una base. Por lo tanto, tomando `df.shape[0]` se calcula la cantidad de filas de la base `df` y por lo tanto, la cantidad de individuos.\n",
        "Para contar la cantidad de mujeres, por ejemplo, se puede recorrer todas las filas de \"Gender\" viendo en cada instancia si el valor coincide con \"Female\". Cuando se suman esos valores, se obtiene la cantidad de mujeres: `np.sum(df[\"Gender\"]==\"Female\")`. El valor de referencia sería `value=0.5` y determinar la hipótesis alternativa correspondiente. Utilizar el `help` para ver cómo funciona el comando.\n"
      ],
      "metadata": {
        "id": "2SpWrlegoYaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest"
      ],
      "metadata": {
        "id": "O55aSZ9_rQ6x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(proportions_ztest)"
      ],
      "metadata": {
        "id": "o4LmVogM63AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f7db2d-99fb-4753-897d-08f175009630"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function proportions_ztest in module statsmodels.stats.proportion:\n",
            "\n",
            "proportions_ztest(count, nobs, value=None, alternative='two-sided', prop_var=False)\n",
            "    Test for proportions based on normal (z) test\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    count : {int, array_like}\n",
            "        the number of successes in nobs trials. If this is array_like, then\n",
            "        the assumption is that this represents the number of successes for\n",
            "        each independent sample\n",
            "    nobs : {int, array_like}\n",
            "        the number of trials or observations, with the same length as\n",
            "        count.\n",
            "    value : float, array_like or None, optional\n",
            "        This is the value of the null hypothesis equal to the proportion in the\n",
            "        case of a one sample test. In the case of a two-sample test, the\n",
            "        null hypothesis is that prop[0] - prop[1] = value, where prop is the\n",
            "        proportion in the two samples. If not provided value = 0 and the null\n",
            "        is prop[0] = prop[1]\n",
            "    alternative : str in ['two-sided', 'smaller', 'larger']\n",
            "        The alternative hypothesis can be either two-sided or one of the one-\n",
            "        sided tests, smaller means that the alternative hypothesis is\n",
            "        ``prop < value`` and larger means ``prop > value``. In the two sample\n",
            "        test, smaller means that the alternative hypothesis is ``p1 < p2`` and\n",
            "        larger means ``p1 > p2`` where ``p1`` is the proportion of the first\n",
            "        sample and ``p2`` of the second one.\n",
            "    prop_var : False or float in (0, 1)\n",
            "        If prop_var is false, then the variance of the proportion estimate is\n",
            "        calculated based on the sample proportion. Alternatively, a proportion\n",
            "        can be specified to calculate this variance. Common use case is to\n",
            "        use the proportion under the Null hypothesis to specify the variance\n",
            "        of the proportion estimate.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    zstat : float\n",
            "        test statistic for the z-test\n",
            "    p-value : float\n",
            "        p-value for the z-test\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> count = 5\n",
            "    >>> nobs = 83\n",
            "    >>> value = .05\n",
            "    >>> stat, pval = proportions_ztest(count, nobs, value)\n",
            "    >>> print('{0:0.3f}'.format(pval))\n",
            "    0.695\n",
            "    \n",
            "    >>> import numpy as np\n",
            "    >>> from statsmodels.stats.proportion import proportions_ztest\n",
            "    >>> count = np.array([5, 12])\n",
            "    >>> nobs = np.array([83, 99])\n",
            "    >>> stat, pval = proportions_ztest(count, nobs)\n",
            "    >>> print('{0:0.3f}'.format(pval))\n",
            "    0.159\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    This uses a simple normal test for proportions. It should be the same as\n",
            "    running the mean z-test on the data encoded 1 for event and 0 for no event\n",
            "    so that the sum corresponds to the count.\n",
            "    \n",
            "    In the one and two sample cases with two-sided alternative, this test\n",
            "    produces the same p-value as ``proportions_chisquare``, since the\n",
            "    chisquare is the distribution of the square of a standard normal\n",
            "    distribution.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Desarrollo Pregunta 1:**"
      ],
      "metadata": {
        "id": "SwXKtYXgsuxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se calcula la proporcion de mujeres sobre el total de individuos\n",
        "np.sum(df[\"Gender\"]==\"Female\")/df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvUNcz0IrEoL",
        "outputId": "88a55ba5-e968-44e9-a17a-809ec309b8ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44983577187220064"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de hipótesis para ver si la proporción de mujeres es significativamente menor al 50%.\n",
        "\"\"\"Detalle de como funciona el comando: Examples\n",
        "    --------\n",
        "    >>> count = 5\n",
        "    >>> nobs = 83\n",
        "    >>> value = .05\n",
        "    >>> stat, pval = proportions_ztest(count, nobs, value)\n",
        "    >>> print('{0:0.3f}'.format(pval))\n",
        "    0.695\n",
        "\n",
        "    >>> import numpy as np\n",
        "    >>> from statsmodels.stats.proportion import proportions_ztest\n",
        "    >>> count = np.array([5, 12])\n",
        "    >>> nobs = np.array([83, 99])\n",
        "    >>> stat, pval = proportions_ztest(count, nobs)\n",
        "    >>> print('{0:0.3f}'.format(pval))\n",
        "    0.159 \"\"\"\n",
        "import numpy as np\n",
        "# Calculamos la cantidad de mujeres\n",
        "tot_mujeres= np.sum(df[\"Gender\"] == \"Female\")\n",
        "\n",
        "# Total de individuos\n",
        "tot_indiv = df.shape[0]\n",
        "\n",
        "# Realizamos el test de hipótesis\n",
        "\"\"\" El valor de alternative es igual a 'smaller' porque la pregunta que se está tratando de responder es si la proporción de mujeres es significativamente menor al 50%.\n",
        "En un test de hipótesis, la hipótesis alternativa es aquella que se quiere demostrar. En este caso, se quiere demostrar que la proporción de mujeres es menor al 50%, por lo que la hipótesis alternativa es 'smaller'.\n",
        "Si la pregunta fuera si la proporción de mujeres es diferente al 50%, entonces el valor de alternative sería 'two-sided' \"\"\"\n",
        "count = tot_mujeres\n",
        "nobs = tot_indiv\n",
        "value = 0.5\n",
        "alternative = 'smaller'  # La hipótesis alternativa es que la proporción de mujeres es menor al 50%\n",
        "stat, pval = proportions_ztest(count, nobs, value, alternative=alternative)\n",
        "\n",
        "print(f\"Estadístico de prueba: {stat}\")\n",
        "print(f\"Valor p: {pval}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmwyRmAQurbj",
        "outputId": "697180c3-7def-4bf0-cb5f-c247d53b85ab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estadístico de prueba: -8.252652095126743\n",
            "Valor p: 7.745877354389196e-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta 1:** Investigando sobre el resultado surge que el valor p es 7.74e-17(0.000000000000000077458), que es mucho menor que el nivel de significancia usual de 0.05. Esto significa que se rechaza la hipótesis nula de que la proporción de mujeres es igual a 0.5.\n",
        "\n",
        "El estadístico de prueba es -8.25, que es un valor negativo grande. Esto indica que la proporción de mujeres en la muestra es significativamente menor que 0.5.\n",
        "\n",
        "Por lo tanto, se puede concluir que la proporción de mujeres es significativamente menor al 50% en la población de la que se extrajo la muestra.\n",
        "**Aclaración teorica sobre el valor p(p-value) :** representa la probabilidad de observar los resultados obtenidos en la muestra, o resultados aún más extremos, si la hipótesis nula fuera cierta.\n",
        "\n",
        "En otras palabras, si la proporción de mujeres en la población realmente fuera del 50%, el valor p indica cuán probable sería obtener una muestra con una proporción de mujeres tan baja (o más baja) como la observada en tus datos.\n",
        "\n",
        "Un valor p pequeño (generalmente menor a 0.05) indica que es poco probable obtener los resultados observados si la hipótesis nula fuera cierta. Esto proporciona evidencia para rechazar la hipótesis nula y apoyar la hipótesis alternativa."
      ],
      "metadata": {
        "id": "eU-noGBq7yRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 2\n",
        "\n",
        "Notemos que el porcentaje identificado como `Other` en la base es pequeño y no es un número que permita obtener conclusiones estadísticas pertinentes.\n",
        "\n",
        "Realizar un test de hipótesis para ver si el salario medio de los hombres es **mayor** que el de las mujeres, según estos datos.\n",
        "\n",
        "*Ayuda:* Se están evaluando medias, no porcentajes, por lo que se usa la función provista. Para comparar las medias, se deben pasar dos conjuntos de datos como argumento. Para identificar, por ejemplo, los datos de salarios sólo de las mujeres, se puede utilizar el siguiente comando: `df.Salary[df[\"Gender\"]==\"Female\"]`"
      ],
      "metadata": {
        "id": "GaH1XdyQrqJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.weightstats import ztest"
      ],
      "metadata": {
        "id": "avstO5xRtmG9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(ztest)"
      ],
      "metadata": {
        "id": "xI-R9Y6KuX5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2a1199-f2e8-4ae7-8559-d874192453a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function ztest in module statsmodels.stats.weightstats:\n",
            "\n",
            "ztest(x1, x2=None, value=0, alternative='two-sided', usevar='pooled', ddof=1.0)\n",
            "    test for mean based on normal distribution, one or two samples\n",
            "    \n",
            "    In the case of two samples, the samples are assumed to be independent.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    x1 : array_like, 1-D or 2-D\n",
            "        first of the two independent samples\n",
            "    x2 : array_like, 1-D or 2-D\n",
            "        second of the two independent samples\n",
            "    value : float\n",
            "        In the one sample case, value is the mean of x1 under the Null\n",
            "        hypothesis.\n",
            "        In the two sample case, value is the difference between mean of x1 and\n",
            "        mean of x2 under the Null hypothesis. The test statistic is\n",
            "        `x1_mean - x2_mean - value`.\n",
            "    alternative : str\n",
            "        The alternative hypothesis, H1, has to be one of the following\n",
            "    \n",
            "           'two-sided': H1: difference in means not equal to value (default)\n",
            "           'larger' :   H1: difference in means larger than value\n",
            "           'smaller' :  H1: difference in means smaller than value\n",
            "    \n",
            "    usevar : str, 'pooled' or 'unequal'\n",
            "        If ``pooled``, then the standard deviation of the samples is assumed to be\n",
            "        the same. If ``unequal``, then the standard deviation of the sample is\n",
            "        assumed to be different.\n",
            "    ddof : int\n",
            "        Degrees of freedom use in the calculation of the variance of the mean\n",
            "        estimate. In the case of comparing means this is one, however it can\n",
            "        be adjusted for testing other statistics (proportion, correlation)\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    tstat : float\n",
            "        test statistic\n",
            "    pvalue : float\n",
            "        pvalue of the t-test\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    usevar can be pooled or unequal in two sample case\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Desarrollo pregunta 2:** Soporte teorico: La hipótesis nula es un concepto fundamental en las pruebas de hipótesis estadísticas.\n",
        "\n",
        "En términos simples, la hipótesis nula es una afirmación que se asume como verdadera para empezar. Es la afirmación que se está tratando de refutar o \"anular\" con la prueba de hipótesis.\n",
        "\n",
        "Generalmente, la hipótesis nula plantea que no hay diferencia, efecto o relación entre las variables que se están estudiando.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "Cuanda estamos  estudiando si existe una diferencia en el salario medio entre hombres y mujeres, la hipótesis nula sería: \"No hay diferencia en el salario medio entre hombres y mujeres\".\n",
        "\n",
        "Durante la prueba de hipótesis, se busca evidencia para rechazar la hipótesis nula. Si la evidencia es lo suficientemente fuerte (valor p bajo), se rechaza la hipótesis nula en favor de la hipótesis alternativa (que sí plantea una diferencia, efecto o relación).\n",
        "\n",
        "Es importante recordar que no se puede \"probar\" la hipótesis nula. Solo se puede rechazar o no rechazar con cierto grado de confianza."
      ],
      "metadata": {
        "id": "xtzpsliCGsud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.weightstats import ztest\n",
        "df.Salary[df[\"Gender\"]==\"Female\"]\n",
        "df.Salary[df[\"Gender\"]==\"Male\"]\n",
        "ztest(df.Salary[df[\"Gender\"]==\"Female\"], df.Salary[df[\"Gender\"]==\"Male\"])\n",
        "# referencia de codigo : ztest(x1, x2=None, value=0, alternative='two-sided', usevar='pooled', ddof=1.0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afyyGKAsGzFd",
        "outputId": "184fa00d-7a88-41ca-9d31-b435e6b1bfb6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-10.489305680117718, 9.673662834272327e-26)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta pregunta 2:** (-10.489305680117718,\n",
        " 9.673662834272327e-26) son los resultados de la prueba ztest que compara el salario medio de hombres y mujeres. El valor -10.489... (Estadístico de prueba) es grande y negativo  e  indica que la media del primer grupo (mujeres) es considerablemente menor que la media del segundo grupo (hombres).\n",
        "9.673...e-26 (Valor p): Este valor es extremadamente pequeño (prácticamente cero).\n",
        "Conclusión: Dado que el valor p es mucho menor que el nivel de significancia usual de 0.05, se rechaza la hipótesis nula de que no hay diferencia en los salarios medios.\n",
        "\n",
        "En este caso, la evidencia sugiere que existe una diferencia estadísticamente significativa entre los salarios de hombres y mujeres, y que el salario medio de las mujeres es significativamente menor al de los hombres."
      ],
      "metadata": {
        "id": "vIgiLMt_HrF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acá calculamos el salario medio para hombres y para mujeres solo para observar la afirmacion de la respuesta 2\n",
        "\n",
        "#salario medio para hombres\n",
        "mean_salary_male = df.Salary[df[\"Gender\"] == \"Male\"].mean()\n",
        "print(f\"Salario medio para hombres: {mean_salary_male}\")\n",
        "\n",
        "#salario medio para mujeres\n",
        "mean_salary_female = df.Salary[df[\"Gender\"] == \"Female\"].mean()\n",
        "print(f\"Salario medio para mujeres: {mean_salary_female}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPfJ0dE8LJOF",
        "outputId": "f2705e34-9f19-4254-e7a0-2d5b12016a5a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salario medio para hombres: 121395.69763007356\n",
            "Salario medio para mujeres: 107888.99867241952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 3\n",
        "\n",
        "Realizar un test de ANOVA para ver si el salario medio cambia con los distintos niveles educativos. Utilizar la comparación múltiple para ver cuáles son diferentes entre sí\n",
        "\n",
        "*Ayuda:* Los datos deben pasarse en una **lista**. Entonces, habría que definir previamente los datos de salario para cada nivel educativo. Para identificar el salario por cada nivel educativo, se puede usar la ayuda anterior reemplazando \"Gender\" por \"Education New\" y \"Female\" por \"High School\" para obtener los salarios de personas con título secundario completo. Para la comparación múltiple, se pueden usar directamente las columnas `df[\"Salary\"]` (datos) y `df[\"Education New\"]` (grupos)."
      ],
      "metadata": {
        "id": "bVYugQgQt49h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.oneway import anova_oneway\n",
        "from statsmodels.sandbox.stats.multicomp import MultiComparison"
      ],
      "metadata": {
        "id": "K59yTk5kAr5y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo pregunta 3: Soporte teorico según lo investigado:Un test ANOVA (ANalysis Of VAriance) se utiliza para comparar las medias de tres o más grupos. Determina si existe una diferencia estadísticamente significativa entre las medias de los grupos o si se trata de variaciones aleatorias"
      ],
      "metadata": {
        "id": "O2i5cPXHN0cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de salarios de individuos con título secundario completo\n",
        "x1= df.Salary[df[\"Education New\"] == \"High School\"]\n",
        "# Datos de salarios de individuos con título de grado completo\n",
        "x2= df.Salary[df[\"Education New\"] == \"Bachelor's\"]\n",
        "# Datos de salarios de individuos con título de maestría completo\n",
        "x3= df.Salary[df[\"Education New\"] == \"Master's\"]\n",
        "# Datos de salarios de individuos con título de doctorado completo\n",
        "x4= df.Salary[df[\"Education New\"] == \"PhD\"]\n",
        "print(anova_oneway([x1,x2,x3,x4]))\n",
        "MC=MultiComparison(df['Salary'], df['Education New'])\n",
        "print(MC.tukeyhsd())"
      ],
      "metadata": {
        "id": "noU_wTvUwHDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb595830-72a9-4473-a8a2-f6e855b1db72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "statistic = 3041.3825616847093\n",
            "pvalue = 0.0\n",
            "df = (3.0, 2121.411447112915)\n",
            "df_num = 3.0\n",
            "df_denom = 2121.411447112915\n",
            "nobs_t = 6698.0\n",
            "n_groups = 4\n",
            "means = [ 36706.69419643  95082.90863952 130112.05645161 165651.45799854]\n",
            "nobs = [ 448. 3021. 1860. 1369.]\n",
            "vars_ = [5.08463264e+08 1.94408596e+09 1.65167616e+09 1.17921854e+09]\n",
            "use_var = unequal\n",
            "welch_correction = True\n",
            "tuple = (3041.3825616847093, 0.0)\n",
            "          Multiple Comparison of Means - Tukey HSD, FWER=0.05           \n",
            "========================================================================\n",
            "   group1      group2     meandiff  p-adj    lower       upper    reject\n",
            "------------------------------------------------------------------------\n",
            " Bachelor's High School -58376.2144   0.0 -63597.4627 -53154.9661   True\n",
            " Bachelor's    Master's  35029.1478   0.0  31989.5989  38068.6967   True\n",
            " Bachelor's         PhD  70568.5494   0.0  67208.5303  73928.5684   True\n",
            "High School    Master's  93405.3623   0.0  87977.7478  98832.9767   True\n",
            "High School         PhD 128944.7638   0.0 123331.3986  134558.129   True\n",
            "   Master's         PhD  35539.4015   0.0  31866.8966  39211.9065   True\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(anova_oneway)\n",
        "help(MultiComparison)"
      ],
      "metadata": {
        "id": "G55QyX4Rxcz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6b3dcacb-1fcd-4b7d-a259-38131b8762db"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function anova_oneway in module statsmodels.stats.oneway:\n",
            "\n",
            "anova_oneway(data, groups=None, use_var='unequal', welch_correction=True, trim_frac=0)\n",
            "    Oneway Anova\n",
            "    \n",
            "    This implements standard anova, Welch and Brown-Forsythe, and trimmed\n",
            "    (Yuen) variants of those.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : tuple of array_like or DataFrame or Series\n",
            "        Data for k independent samples, with k >= 2.\n",
            "        The data can be provided as a tuple or list of arrays or in long\n",
            "        format with outcome observations in ``data`` and group membership in\n",
            "        ``groups``.\n",
            "    groups : ndarray or Series\n",
            "        If data is in long format, then groups is needed as indicator to which\n",
            "        group or sample and observations belongs.\n",
            "    use_var : {\"unequal\", \"equal\" or \"bf\"}\n",
            "        `use_var` specified how to treat heteroscedasticity, unequal variance,\n",
            "        across samples. Three approaches are available\n",
            "    \n",
            "        \"unequal\" : Variances are not assumed to be equal across samples.\n",
            "            Heteroscedasticity is taken into account with Welch Anova and\n",
            "            Satterthwaite-Welch degrees of freedom.\n",
            "            This is the default.\n",
            "        \"equal\" : Variances are assumed to be equal across samples.\n",
            "            This is the standard Anova.\n",
            "        \"bf\" : Variances are not assumed to be equal across samples.\n",
            "            The method is Browne-Forsythe (1971) for testing equality of means\n",
            "            with the corrected degrees of freedom by Merothra. The original BF\n",
            "            degrees of freedom are available as additional attributes in the\n",
            "            results instance, ``df_denom2`` and ``p_value2``.\n",
            "    \n",
            "    welch_correction : bool\n",
            "        If this is false, then the Welch correction to the test statistic is\n",
            "        not included. This allows the computation of an effect size measure\n",
            "        that corresponds more closely to Cohen's f.\n",
            "    trim_frac : float in [0, 0.5)\n",
            "        Optional trimming for Anova with trimmed mean and winsorized variances.\n",
            "        With the default trim_frac equal to zero, the oneway Anova statistics\n",
            "        are computed without trimming. If `trim_frac` is larger than zero,\n",
            "        then the largest and smallest observations in each sample are trimmed.\n",
            "        The number of trimmed observations is the fraction of number of\n",
            "        observations in the sample truncated to the next lower integer.\n",
            "        `trim_frac` has to be smaller than 0.5, however, if the fraction is\n",
            "        so large that there are not enough observations left over, then `nan`\n",
            "        will be returned.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    res : results instance\n",
            "        The returned HolderTuple instance has the following main attributes\n",
            "        and some additional information in other attributes.\n",
            "    \n",
            "        statistic : float\n",
            "            Test statistic for k-sample mean comparison which is approximately\n",
            "            F-distributed.\n",
            "        pvalue : float\n",
            "            If ``use_var=\"bf\"``, then the p-value is based on corrected\n",
            "            degrees of freedom following Mehrotra 1997.\n",
            "        pvalue2 : float\n",
            "            This is the p-value based on degrees of freedom as in\n",
            "            Brown-Forsythe 1974 and is only available if ``use_var=\"bf\"``.\n",
            "        df = (df_denom, df_num) : tuple of floats\n",
            "            Degreeds of freedom for the F-distribution depend on ``use_var``.\n",
            "            If ``use_var=\"bf\"``, then `df_denom` is for Mehrotra p-values\n",
            "            `df_denom2` is available for Brown-Forsythe 1974 p-values.\n",
            "            `df_num` is the same numerator degrees of freedom for both\n",
            "            p-values.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Welch's anova is correctly sized (not liberal or conservative) in smaller\n",
            "    samples if the distribution of the samples is not very far away from the\n",
            "    normal distribution. The test can become liberal if the data is strongly\n",
            "    skewed. Welch's Anova can also be correctly sized for discrete\n",
            "    distributions with finite support, like Lickert scale data.\n",
            "    The trimmed version is robust to many non-normal distributions, it stays\n",
            "    correctly sized in many cases, and is more powerful in some cases with\n",
            "    skewness or heavy tails.\n",
            "    \n",
            "    Trimming is currently based on the integer part of ``nobs * trim_frac``.\n",
            "    The default might change to including fractional observations as in the\n",
            "    original articles by Yuen.\n",
            "    \n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    anova_generic\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    Brown, Morton B., and Alan B. Forsythe. 1974. “The Small Sample Behavior\n",
            "    of Some Statistics Which Test the Equality of Several Means.”\n",
            "    Technometrics 16 (1) (February 1): 129–132. doi:10.2307/1267501.\n",
            "    \n",
            "    Mehrotra, Devan V. 1997. “Improving the Brown-Forsythe Solution to the\n",
            "    Generalized Behrens-Fisher Problem.” Communications in Statistics -\n",
            "    Simulation and Computation 26 (3): 1139–1145.\n",
            "    doi:10.1080/03610919708813431.\n",
            "\n",
            "Help on class MultiComparison in module statsmodels.sandbox.stats.multicomp:\n",
            "\n",
            "class MultiComparison(builtins.object)\n",
            " |  MultiComparison(data, groups, group_order=None)\n",
            " |  \n",
            " |  Tests for multiple comparisons\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  data : ndarray\n",
            " |      independent data samples\n",
            " |  groups : ndarray\n",
            " |      group labels corresponding to each data point\n",
            " |  group_order : list[str], optional\n",
            " |      the desired order for the group mean results to be reported in. If\n",
            " |      not specified, results are reported in increasing order.\n",
            " |      If group_order does not contain all labels that are in groups, then\n",
            " |      only those observations are kept that have a label in group_order.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, data, groups, group_order=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  allpairtest(self, testfunc, alpha=0.05, method='bonf', pvalidx=1)\n",
            " |      run a pairwise test on all pairs with multiple test correction\n",
            " |      \n",
            " |      The statistical test given in testfunc is calculated for all pairs\n",
            " |      and the p-values are adjusted by methods in multipletests. The p-value\n",
            " |      correction is generic and based only on the p-values, and does not\n",
            " |      take any special structure of the hypotheses into account.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      testfunc : function\n",
            " |          A test function for two (independent) samples. It is assumed that\n",
            " |          the return value on position pvalidx is the p-value.\n",
            " |      alpha : float\n",
            " |          familywise error rate\n",
            " |      method : str\n",
            " |          This specifies the method for the p-value correction. Any method\n",
            " |          of multipletests is possible.\n",
            " |      pvalidx : int (default: 1)\n",
            " |          position of the p-value in the return of testfunc\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      sumtab : SimpleTable instance\n",
            " |          summary table for printing\n",
            " |      \n",
            " |      errors:  TODO: check if this is still wrong, I think it's fixed.\n",
            " |      results from multipletests are in different order\n",
            " |      pval_corrected can be larger than 1 ???\n",
            " |  \n",
            " |  getranks(self)\n",
            " |      convert data to rankdata and attach\n",
            " |      \n",
            " |      \n",
            " |      This creates rankdata as it is used for non-parametric tests, where\n",
            " |      in the case of ties the average rank is assigned.\n",
            " |  \n",
            " |  kruskal(self, pairs=None, multimethod='T')\n",
            " |      pairwise comparison for kruskal-wallis test\n",
            " |      \n",
            " |      This is just a reimplementation of scipy.stats.kruskal and does\n",
            " |      not yet use a multiple comparison correction.\n",
            " |  \n",
            " |  tukeyhsd(self, alpha=0.05)\n",
            " |      Tukey's range test to compare means of all pairs of groups\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      alpha : float, optional\n",
            " |          Value of FWER at which to calculate HSD.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      results : TukeyHSDResults instance\n",
            " |          A results class containing relevant data and some post-hoc\n",
            " |          calculations\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 4\n",
        "\n",
        "Testear si la variable de años de experiencia tiene distribución normal y obtenga alguna conclusión. Hacer un histograma de la variable para comparar con los resultados del test.\n",
        "\n"
      ],
      "metadata": {
        "id": "tB1Oz1MfxQ8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import shapiro"
      ],
      "metadata": {
        "id": "YvWCeCr8A1ZU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(shapiro)\n",
        "help(plt.hist)"
      ],
      "metadata": {
        "id": "B3L-FGJAlK8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3e74ea15-66b0-464f-ce9c-7d0e4f94bd25"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function shapiro in module scipy.stats._morestats:\n",
            "\n",
            "shapiro(x, *, axis=None, nan_policy='propagate', keepdims=False)\n",
            "    Perform the Shapiro-Wilk test for normality.\n",
            "    \n",
            "    The Shapiro-Wilk test tests the null hypothesis that the\n",
            "    data was drawn from a normal distribution.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    x : array_like\n",
            "        Array of sample data.\n",
            "    axis : int or None, default: None\n",
            "        If an int, the axis of the input along which to compute the statistic.\n",
            "        The statistic of each axis-slice (e.g. row) of the input will appear in a\n",
            "        corresponding element of the output.\n",
            "        If ``None``, the input will be raveled before computing the statistic.\n",
            "    nan_policy : {'propagate', 'omit', 'raise'}\n",
            "        Defines how to handle input NaNs.\n",
            "        \n",
            "        - ``propagate``: if a NaN is present in the axis slice (e.g. row) along\n",
            "          which the  statistic is computed, the corresponding entry of the output\n",
            "          will be NaN.\n",
            "        - ``omit``: NaNs will be omitted when performing the calculation.\n",
            "          If insufficient data remains in the axis slice along which the\n",
            "          statistic is computed, the corresponding entry of the output will be\n",
            "          NaN.\n",
            "        - ``raise``: if a NaN is present, a ``ValueError`` will be raised.\n",
            "    keepdims : bool, default: False\n",
            "        If this is set to True, the axes which are reduced are left\n",
            "        in the result as dimensions with size one. With this option,\n",
            "        the result will broadcast correctly against the input array.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    statistic : float\n",
            "        The test statistic.\n",
            "    p-value : float\n",
            "        The p-value for the hypothesis test.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    \n",
            "    :func:`anderson`\n",
            "        The Anderson-Darling test for normality\n",
            "    :func:`kstest`\n",
            "        The Kolmogorov-Smirnov test for goodness of fit.\n",
            "    \n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    The algorithm used is described in [4]_ but censoring parameters as\n",
            "    described are not implemented. For N > 5000 the W test statistic is\n",
            "    accurate, but the p-value may not be.\n",
            "    \n",
            "    Beginning in SciPy 1.9, ``np.matrix`` inputs (not recommended for new\n",
            "    code) are converted to ``np.ndarray`` before the calculation is performed. In\n",
            "    this case, the output will be a scalar or ``np.ndarray`` of appropriate shape\n",
            "    rather than a 2D ``np.matrix``. Similarly, while masked elements of masked\n",
            "    arrays are ignored, the output will be a scalar or ``np.ndarray`` rather than a\n",
            "    masked array with ``mask=False``.\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    .. [1] https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
            "           :doi:`10.18434/M32189`\n",
            "    .. [2] Shapiro, S. S. & Wilk, M.B, \"An analysis of variance test for\n",
            "           normality (complete samples)\", Biometrika, 1965, Vol. 52,\n",
            "           pp. 591-611, :doi:`10.2307/2333709`\n",
            "    .. [3] Razali, N. M. & Wah, Y. B., \"Power comparisons of Shapiro-Wilk,\n",
            "           Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests\", Journal\n",
            "           of Statistical Modeling and Analytics, 2011, Vol. 2, pp. 21-33.\n",
            "    .. [4] Royston P., \"Remark AS R94: A Remark on Algorithm AS 181: The\n",
            "           W-test for Normality\", 1995, Applied Statistics, Vol. 44,\n",
            "           :doi:`10.2307/2986146`\n",
            "    .. [5] Phipson B., and Smyth, G. K., \"Permutation P-values Should Never Be\n",
            "           Zero: Calculating Exact P-values When Permutations Are Randomly\n",
            "           Drawn\", Statistical Applications in Genetics and Molecular Biology,\n",
            "           2010, Vol.9, :doi:`10.2202/1544-6115.1585`\n",
            "    .. [6] Panagiotakos, D. B., \"The value of p-value in biomedical\n",
            "           research\", The Open Cardiovascular Medicine Journal, 2008, Vol.2,\n",
            "           pp. 97-99, :doi:`10.2174/1874192400802010097`\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    Suppose we wish to infer from measurements whether the weights of adult\n",
            "    human males in a medical study are not normally distributed [2]_.\n",
            "    The weights (lbs) are recorded in the array ``x`` below.\n",
            "    \n",
            "    >>> import numpy as np\n",
            "    >>> x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])\n",
            "    \n",
            "    The normality test of [1]_ and [2]_ begins by computing a statistic based\n",
            "    on the relationship between the observations and the expected order\n",
            "    statistics of a normal distribution.\n",
            "    \n",
            "    >>> from scipy import stats\n",
            "    >>> res = stats.shapiro(x)\n",
            "    >>> res.statistic\n",
            "    0.7888147830963135\n",
            "    \n",
            "    The value of this statistic tends to be high (close to 1) for samples drawn\n",
            "    from a normal distribution.\n",
            "    \n",
            "    The test is performed by comparing the observed value of the statistic\n",
            "    against the null distribution: the distribution of statistic values formed\n",
            "    under the null hypothesis that the weights were drawn from a normal\n",
            "    distribution. For this normality test, the null distribution is not easy to\n",
            "    calculate exactly, so it is usually approximated by Monte Carlo methods,\n",
            "    that is, drawing many samples of the same size as ``x`` from a normal\n",
            "    distribution and computing the values of the statistic for each.\n",
            "    \n",
            "    >>> def statistic(x):\n",
            "    ...     # Get only the `shapiro` statistic; ignore its p-value\n",
            "    ...     return stats.shapiro(x).statistic\n",
            "    >>> ref = stats.monte_carlo_test(x, stats.norm.rvs, statistic,\n",
            "    ...                              alternative='less')\n",
            "    >>> import matplotlib.pyplot as plt\n",
            "    >>> fig, ax = plt.subplots(figsize=(8, 5))\n",
            "    >>> bins = np.linspace(0.65, 1, 50)\n",
            "    >>> def plot(ax):  # we'll reuse this\n",
            "    ...     ax.hist(ref.null_distribution, density=True, bins=bins)\n",
            "    ...     ax.set_title(\"Shapiro-Wilk Test Null Distribution \\n\"\n",
            "    ...                  \"(Monte Carlo Approximation, 11 Observations)\")\n",
            "    ...     ax.set_xlabel(\"statistic\")\n",
            "    ...     ax.set_ylabel(\"probability density\")\n",
            "    >>> plot(ax)\n",
            "    >>> plt.show()\n",
            "    \n",
            "    The comparison is quantified by the p-value: the proportion of values in\n",
            "    the null distribution less than or equal to the observed value of the\n",
            "    statistic.\n",
            "    \n",
            "    >>> fig, ax = plt.subplots(figsize=(8, 5))\n",
            "    >>> plot(ax)\n",
            "    >>> annotation = (f'p-value={res.pvalue:.6f}\\n(highlighted area)')\n",
            "    >>> props = dict(facecolor='black', width=1, headwidth=5, headlength=8)\n",
            "    >>> _ = ax.annotate(annotation, (0.75, 0.1), (0.68, 0.7), arrowprops=props)\n",
            "    >>> i_extreme = np.where(bins <= res.statistic)[0]\n",
            "    >>> for i in i_extreme:\n",
            "    ...     ax.patches[i].set_color('C1')\n",
            "    >>> plt.xlim(0.65, 0.9)\n",
            "    >>> plt.ylim(0, 4)\n",
            "    >>> plt.show\n",
            "    >>> res.pvalue\n",
            "    0.006703833118081093\n",
            "    \n",
            "    If the p-value is \"small\" - that is, if there is a low probability of\n",
            "    sampling data from a normally distributed population that produces such an\n",
            "    extreme value of the statistic - this may be taken as evidence against\n",
            "    the null hypothesis in favor of the alternative: the weights were not\n",
            "    drawn from a normal distribution. Note that:\n",
            "    \n",
            "    - The inverse is not true; that is, the test is not used to provide\n",
            "      evidence *for* the null hypothesis.\n",
            "    - The threshold for values that will be considered \"small\" is a choice that\n",
            "      should be made before the data is analyzed [5]_ with consideration of the\n",
            "      risks of both false positives (incorrectly rejecting the null hypothesis)\n",
            "      and false negatives (failure to reject a false null hypothesis).\n",
            "\n",
            "Help on function hist in module matplotlib.pyplot:\n",
            "\n",
            "hist(x, bins=None, range=None, density=False, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, *, data=None, **kwargs)\n",
            "    Compute and plot a histogram.\n",
            "    \n",
            "    This method uses `numpy.histogram` to bin the data in *x* and count the\n",
            "    number of values in each bin, then draws the distribution either as a\n",
            "    `.BarContainer` or `.Polygon`. The *bins*, *range*, *density*, and\n",
            "    *weights* parameters are forwarded to `numpy.histogram`.\n",
            "    \n",
            "    If the data has already been binned and counted, use `~.bar` or\n",
            "    `~.stairs` to plot the distribution::\n",
            "    \n",
            "        counts, bins = np.histogram(x)\n",
            "        plt.stairs(counts, bins)\n",
            "    \n",
            "    Alternatively, plot pre-computed bins and counts using ``hist()`` by\n",
            "    treating each bin as a single point with a weight equal to its count::\n",
            "    \n",
            "        plt.hist(bins[:-1], bins, weights=counts)\n",
            "    \n",
            "    The data input *x* can be a singular array, a list of datasets of\n",
            "    potentially different lengths ([*x0*, *x1*, ...]), or a 2D ndarray in\n",
            "    which each column is a dataset. Note that the ndarray form is\n",
            "    transposed relative to the list form. If the input is an array, then\n",
            "    the return value is a tuple (*n*, *bins*, *patches*); if the input is a\n",
            "    sequence of arrays, then the return value is a tuple\n",
            "    ([*n0*, *n1*, ...], *bins*, [*patches0*, *patches1*, ...]).\n",
            "    \n",
            "    Masked arrays are not supported.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    x : (n,) array or sequence of (n,) arrays\n",
            "        Input values, this takes either a single array or a sequence of\n",
            "        arrays which are not required to be of the same length.\n",
            "    \n",
            "    bins : int or sequence or str, default: :rc:`hist.bins`\n",
            "        If *bins* is an integer, it defines the number of equal-width bins\n",
            "        in the range.\n",
            "    \n",
            "        If *bins* is a sequence, it defines the bin edges, including the\n",
            "        left edge of the first bin and the right edge of the last bin;\n",
            "        in this case, bins may be unequally spaced.  All but the last\n",
            "        (righthand-most) bin is half-open.  In other words, if *bins* is::\n",
            "    \n",
            "            [1, 2, 3, 4]\n",
            "    \n",
            "        then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n",
            "        the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n",
            "        *includes* 4.\n",
            "    \n",
            "        If *bins* is a string, it is one of the binning strategies\n",
            "        supported by `numpy.histogram_bin_edges`: 'auto', 'fd', 'doane',\n",
            "        'scott', 'stone', 'rice', 'sturges', or 'sqrt'.\n",
            "    \n",
            "    range : tuple or None, default: None\n",
            "        The lower and upper range of the bins. Lower and upper outliers\n",
            "        are ignored. If not provided, *range* is ``(x.min(), x.max())``.\n",
            "        Range has no effect if *bins* is a sequence.\n",
            "    \n",
            "        If *bins* is a sequence or *range* is specified, autoscaling\n",
            "        is based on the specified bin range instead of the\n",
            "        range of x.\n",
            "    \n",
            "    density : bool, default: False\n",
            "        If ``True``, draw and return a probability density: each bin\n",
            "        will display the bin's raw count divided by the total number of\n",
            "        counts *and the bin width*\n",
            "        (``density = counts / (sum(counts) * np.diff(bins))``),\n",
            "        so that the area under the histogram integrates to 1\n",
            "        (``np.sum(density * np.diff(bins)) == 1``).\n",
            "    \n",
            "        If *stacked* is also ``True``, the sum of the histograms is\n",
            "        normalized to 1.\n",
            "    \n",
            "    weights : (n,) array-like or None, default: None\n",
            "        An array of weights, of the same shape as *x*.  Each value in\n",
            "        *x* only contributes its associated weight towards the bin count\n",
            "        (instead of 1).  If *density* is ``True``, the weights are\n",
            "        normalized, so that the integral of the density over the range\n",
            "        remains 1.\n",
            "    \n",
            "    cumulative : bool or -1, default: False\n",
            "        If ``True``, then a histogram is computed where each bin gives the\n",
            "        counts in that bin plus all bins for smaller values. The last bin\n",
            "        gives the total number of datapoints.\n",
            "    \n",
            "        If *density* is also ``True`` then the histogram is normalized such\n",
            "        that the last bin equals 1.\n",
            "    \n",
            "        If *cumulative* is a number less than 0 (e.g., -1), the direction\n",
            "        of accumulation is reversed.  In this case, if *density* is also\n",
            "        ``True``, then the histogram is normalized such that the first bin\n",
            "        equals 1.\n",
            "    \n",
            "    bottom : array-like, scalar, or None, default: None\n",
            "        Location of the bottom of each bin, i.e. bins are drawn from\n",
            "        ``bottom`` to ``bottom + hist(x, bins)`` If a scalar, the bottom\n",
            "        of each bin is shifted by the same amount. If an array, each bin\n",
            "        is shifted independently and the length of bottom must match the\n",
            "        number of bins. If None, defaults to 0.\n",
            "    \n",
            "    histtype : {'bar', 'barstacked', 'step', 'stepfilled'}, default: 'bar'\n",
            "        The type of histogram to draw.\n",
            "    \n",
            "        - 'bar' is a traditional bar-type histogram.  If multiple data\n",
            "          are given the bars are arranged side by side.\n",
            "        - 'barstacked' is a bar-type histogram where multiple\n",
            "          data are stacked on top of each other.\n",
            "        - 'step' generates a lineplot that is by default unfilled.\n",
            "        - 'stepfilled' generates a lineplot that is by default filled.\n",
            "    \n",
            "    align : {'left', 'mid', 'right'}, default: 'mid'\n",
            "        The horizontal alignment of the histogram bars.\n",
            "    \n",
            "        - 'left': bars are centered on the left bin edges.\n",
            "        - 'mid': bars are centered between the bin edges.\n",
            "        - 'right': bars are centered on the right bin edges.\n",
            "    \n",
            "    orientation : {'vertical', 'horizontal'}, default: 'vertical'\n",
            "        If 'horizontal', `~.Axes.barh` will be used for bar-type histograms\n",
            "        and the *bottom* kwarg will be the left edges.\n",
            "    \n",
            "    rwidth : float or None, default: None\n",
            "        The relative width of the bars as a fraction of the bin width.  If\n",
            "        ``None``, automatically compute the width.\n",
            "    \n",
            "        Ignored if *histtype* is 'step' or 'stepfilled'.\n",
            "    \n",
            "    log : bool, default: False\n",
            "        If ``True``, the histogram axis will be set to a log scale.\n",
            "    \n",
            "    color : color or array-like of colors or None, default: None\n",
            "        Color or sequence of colors, one per dataset.  Default (``None``)\n",
            "        uses the standard line color sequence.\n",
            "    \n",
            "    label : str or None, default: None\n",
            "        String, or sequence of strings to match multiple datasets.  Bar\n",
            "        charts yield multiple patches per dataset, but only the first gets\n",
            "        the label, so that `~.Axes.legend` will work as expected.\n",
            "    \n",
            "    stacked : bool, default: False\n",
            "        If ``True``, multiple data are stacked on top of each other If\n",
            "        ``False`` multiple data are arranged side by side if histtype is\n",
            "        'bar' or on top of each other if histtype is 'step'\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    n : array or list of arrays\n",
            "        The values of the histogram bins. See *density* and *weights* for a\n",
            "        description of the possible semantics.  If input *x* is an array,\n",
            "        then this is an array of length *nbins*. If input is a sequence of\n",
            "        arrays ``[data1, data2, ...]``, then this is a list of arrays with\n",
            "        the values of the histograms for each of the arrays in the same\n",
            "        order.  The dtype of the array *n* (or of its element arrays) will\n",
            "        always be float even if no weighting or normalization is used.\n",
            "    \n",
            "    bins : array\n",
            "        The edges of the bins. Length nbins + 1 (nbins left edges and right\n",
            "        edge of last bin).  Always a single array even when multiple data\n",
            "        sets are passed in.\n",
            "    \n",
            "    patches : `.BarContainer` or list of a single `.Polygon` or list of such objects\n",
            "        Container of individual artists used to create the histogram\n",
            "        or list of such containers if there are multiple input datasets.\n",
            "    \n",
            "    Other Parameters\n",
            "    ----------------\n",
            "    data : indexable object, optional\n",
            "        If given, the following parameters also accept a string ``s``, which is\n",
            "        interpreted as ``data[s]`` (unless this raises an exception):\n",
            "    \n",
            "        *x*, *weights*\n",
            "    \n",
            "    **kwargs\n",
            "        `~matplotlib.patches.Patch` properties\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    hist2d : 2D histogram with rectangular bins\n",
            "    hexbin : 2D histogram with hexagonal bins\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    For large numbers of bins (>1000), plotting can be significantly faster\n",
            "    if *histtype* is set to 'step' or 'stepfilled' rather than 'bar' or\n",
            "    'barstacked'.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarollo Pregunta 4:soporte teorico:shapiro es una función en Python que realiza la prueba de Shapiro-Wilk para la normalidad.\n",
        "\n",
        "Esta prueba es una prueba de hipótesis que se utiliza para determinar si una muestra de datos proviene de una población con distribución normal.\n",
        "\n",
        "La función devuelve dos valores: el estadístico de prueba W y el valor p. Si el valor p es menor que un nivel de significancia elegido (por ejemplo, 0.05), entonces se rechaza la hipótesis nula de que los datos provienen de una población con distribución normal. Que una población tiene una distribución normal significa que los valores de la población se distribuyen de forma simétrica alrededor de la media, formando una curva en forma de campana.\n",
        "\n",
        "En una distribución normal, la mayoría de los valores se agrupan cerca de la media, y a medida que los valores se alejan de la media, su frecuencia disminuye.\n",
        "\n",
        "La distribución normal se caracteriza por su media y su desviación estándar. La media es el centro de la distribución, y la desviación estándar mide la dispersión de los datos alrededor de la media.\n",
        "\n",
        "Hay muchas variables en la naturaleza y en la sociedad que siguen una distribución normal, como la altura de las personas, el peso de los objetos, las puntuaciones de los exámenes, etc"
      ],
      "metadata": {
        "id": "-5FKZ_UcOzW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se define la variable año de experienca\n",
        "years = df['Years of Experience']\n",
        "#Seaplica la funcion de Shapiro\n",
        "stat, p = shapiro(years)\n",
        "print('stat=%.3f, p=%.3f' % (stat, p))\n",
        "if p > 0.05:\n",
        "    print('Probably Gaussian')\n",
        "else:\n",
        "    print('Probably not Gaussian')\n",
        "#Luego graficamos el histograma\n",
        "plt.hist(years)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "hDrlrc52k4x1",
        "outputId": "ed83c128-32a6-4d1c-98db-815c018cfc11"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 6698.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stat=0.920, p=0.000\n",
            "Probably not Gaussian\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoC0lEQVR4nO3df3DUdX7H8dfyYxfB/CCEZLM1hIA1GH5EjJLLnHBwpAkhw2mlrQgKnimcXPAqURpy9SBgx6Shw4mW4jgVaaeonB3BHlwZEhByJwEluA0/NAM0GB2yoQeShXAEknz7B8PX7hGE4C6bT3g+Zr4z+/18Pt/v970fPjO85rvf7Dosy7IEAABgkF7hLgAAAKCrCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOP0CXcBodLR0aETJ04oIiJCDocj3OUAAIAbYFmWzp49K4/Ho169rn2fpccGmBMnTigxMTHcZQAAgJvw5Zdf6q677rpmf48NMBEREZIuT0BkZGSYqwEAADfC7/crMTHR/n/8WnpsgLnysVFkZCQBBgAAw1zv8Q8e4gUAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTp9wF2CioYu3hLuELjtelhfuEgAACBruwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCcLgeYqqoqTZs2TR6PRw6HQ5s2bQrodzgcnW4rVqywxwwdOvSq/rKysoDz1NbWavz48erXr58SExNVXl5+c+8QAAD0OF0OMC0tLUpLS9Pq1as77W9sbAzY1q5dK4fDoenTpweMW758ecC4Z5991u7z+/3Kzs5WUlKSampqtGLFCpWUlOiNN97oarkAAKAH6tPVA3Jzc5Wbm3vNfrfbHbD/wQcfaNKkSRo2bFhAe0RExFVjr1i/fr0uXryotWvXyul0auTIkfJ6vVq5cqXmzZvX1ZIBAEAPE9JnYJqamrRlyxbl5+df1VdWVqZBgwZp7NixWrFihdra2uy+6upqTZgwQU6n027LyclRXV2dvv76606v1draKr/fH7ABAICeqct3YLriX//1XxUREaFHH300oP1nP/uZ7r//fsXExGj37t0qLi5WY2OjVq5cKUny+XxKTk4OOCY+Pt7uGzhw4FXXKi0t1bJly0L0TgAAQHcS0gCzdu1azZo1S/369QtoLywstF+PGTNGTqdTP/nJT1RaWiqXy3VT1youLg44r9/vV2Ji4s0VDgAAurWQBZjf/va3qqur04YNG647NiMjQ21tbTp+/LhSUlLkdrvV1NQUMObK/rWem3G5XDcdfgAAgFlC9gzMm2++qfT0dKWlpV13rNfrVa9evRQXFydJyszMVFVVlS5dumSPqaioUEpKSqcfHwEAgNtLlwPMuXPn5PV65fV6JUn19fXyer1qaGiwx/j9fr333nv667/+66uOr66u1iuvvKL//u//1v/8z/9o/fr1WrhwoZ544gk7nMycOVNOp1P5+fk6dOiQNmzYoFWrVgV8RAQAAG5fXf4Iad++fZo0aZK9fyVUzJkzR+vWrZMkvfvuu7IsS48//vhVx7tcLr377rsqKSlRa2urkpOTtXDhwoBwEhUVpW3btqmgoEDp6emKjY3VkiVL+BNqAAAgSXJYlmWFu4hQ8Pv9ioqKUnNzsyIjI4N67qGLtwT1fLfC8bK8cJcAAMB13ej/3/wWEgAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADG6XKAqaqq0rRp0+TxeORwOLRp06aA/qeeekoOhyNgmzJlSsCY06dPa9asWYqMjFR0dLTy8/N17ty5gDG1tbUaP368+vXrp8TERJWXl3f93QEAgB6pywGmpaVFaWlpWr169TXHTJkyRY2Njfb2zjvvBPTPmjVLhw4dUkVFhTZv3qyqqirNmzfP7vf7/crOzlZSUpJqamq0YsUKlZSU6I033uhquQAAoAfq09UDcnNzlZub+61jXC6X3G53p32fffaZtm7dqk8++UQPPPCAJOm1117T1KlT9Y//+I/yeDxav369Ll68qLVr18rpdGrkyJHyer1auXJlQNABAAC3p5A8A7Nz507FxcUpJSVF8+fP16lTp+y+6upqRUdH2+FFkrKystSrVy/t3bvXHjNhwgQ5nU57TE5Ojurq6vT11193es3W1lb5/f6ADQAA9ExBDzBTpkzRv/3bv2n79u36h3/4B+3atUu5ublqb2+XJPl8PsXFxQUc06dPH8XExMjn89lj4uPjA8Zc2b8y5o+VlpYqKirK3hITE4P91gAAQDfR5Y+QrmfGjBn269GjR2vMmDEaPny4du7cqcmTJwf7crbi4mIVFhba+36/nxADAEAPFfI/ox42bJhiY2N19OhRSZLb7dbJkycDxrS1ten06dP2czNut1tNTU0BY67sX+vZGpfLpcjIyIANAAD0TCEPMF999ZVOnTqlhIQESVJmZqbOnDmjmpoae8yOHTvU0dGhjIwMe0xVVZUuXbpkj6moqFBKSooGDhwY6pIBAEA31+UAc+7cOXm9Xnm9XklSfX29vF6vGhoadO7cOS1atEh79uzR8ePHtX37dj388MO6++67lZOTI0m69957NWXKFM2dO1cff/yxPvroIy1YsEAzZsyQx+ORJM2cOVNOp1P5+fk6dOiQNmzYoFWrVgV8RAQAAG5fXQ4w+/bt09ixYzV27FhJUmFhocaOHaslS5aod+/eqq2t1Y9+9CPdc889ys/PV3p6un7729/K5XLZ51i/fr1GjBihyZMna+rUqXrooYcCvuMlKipK27ZtU319vdLT0/X8889ryZIl/Ak1AACQJDksy7LCXUQo+P1+RUVFqbm5OejPwwxdvCWo57sVjpflhbsEAACu60b//+a3kAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADBOn3AXgFtj6OIt4S7hphwvywt3CQCAbogAg27NxOBF6AKA0OMjJAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjdDnAVFVVadq0afJ4PHI4HNq0aZPdd+nSJRUVFWn06NEaMGCAPB6PZs+erRMnTgScY+jQoXI4HAFbWVlZwJja2lqNHz9e/fr1U2JiosrLy2/uHQIAgB6nywGmpaVFaWlpWr169VV958+f1/79+/WLX/xC+/fv1/vvv6+6ujr96Ec/umrs8uXL1djYaG/PPvus3ef3+5Wdna2kpCTV1NRoxYoVKikp0RtvvNHVcgEAQA/Up6sH5ObmKjc3t9O+qKgoVVRUBLT90z/9k8aNG6eGhgYNGTLEbo+IiJDb7e70POvXr9fFixe1du1aOZ1OjRw5Ul6vVytXrtS8efO6WjIAAOhhQv4MTHNzsxwOh6KjowPay8rKNGjQII0dO1YrVqxQW1ub3VddXa0JEybI6XTabTk5Oaqrq9PXX3/d6XVaW1vl9/sDNgAA0DN1+Q5MV1y4cEFFRUV6/PHHFRkZabf/7Gc/0/3336+YmBjt3r1bxcXFamxs1MqVKyVJPp9PycnJAeeKj4+3+wYOHHjVtUpLS7Vs2bIQvhsAANBdhCzAXLp0SX/1V38ly7K0Zs2agL7CwkL79ZgxY+R0OvWTn/xEpaWlcrlcN3W94uLigPP6/X4lJibeXPEAAKBbC0mAuRJevvjiC+3YsSPg7ktnMjIy1NbWpuPHjyslJUVut1tNTU0BY67sX+u5GZfLddPhBwAAmCXoz8BcCS9HjhxRZWWlBg0adN1jvF6vevXqpbi4OElSZmamqqqqdOnSJXtMRUWFUlJSOv34CAAA3F66fAfm3LlzOnr0qL1fX18vr9ermJgYJSQk6C/+4i+0f/9+bd68We3t7fL5fJKkmJgYOZ1OVVdXa+/evZo0aZIiIiJUXV2thQsX6oknnrDDycyZM7Vs2TLl5+erqKhIBw8e1KpVq/TLX/4ySG8bAACYzGFZltWVA3bu3KlJkyZd1T5nzhyVlJRc9fDtFR9++KEmTpyo/fv366c//ak+//xztba2Kjk5WU8++aQKCwsDPgKqra1VQUGBPvnkE8XGxurZZ59VUVHRDdfp9/sVFRWl5ubm636E1VVDF28J6vnQsxwvywt3CQBgrBv9/7vLAcYUBBiECwEGAG7ejf7/zW8hAQAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4XQ4wVVVVmjZtmjwejxwOhzZt2hTQb1mWlixZooSEBN1xxx3KysrSkSNHAsacPn1as2bNUmRkpKKjo5Wfn69z584FjKmtrdX48ePVr18/JSYmqry8vOvvDgAA9EhdDjAtLS1KS0vT6tWrO+0vLy/Xq6++qtdff1179+7VgAEDlJOTowsXLthjZs2apUOHDqmiokKbN29WVVWV5s2bZ/f7/X5lZ2crKSlJNTU1WrFihUpKSvTGG2/cxFsEAAA9jcOyLOumD3Y4tHHjRj3yyCOSLt998Xg8ev755/XCCy9IkpqbmxUfH69169ZpxowZ+uyzz5SamqpPPvlEDzzwgCRp69atmjp1qr766it5PB6tWbNGf/d3fyefzyen0ylJWrx4sTZt2qTPP//8hmrz+/2KiopSc3OzIiMjb/Ytdmro4i1BPR96luNleeEuAQCMdaP/fwf1GZj6+nr5fD5lZWXZbVFRUcrIyFB1dbUkqbq6WtHR0XZ4kaSsrCz16tVLe/futcdMmDDBDi+SlJOTo7q6On399dfBLBkAABioTzBP5vP5JEnx8fEB7fHx8Xafz+dTXFxcYBF9+igmJiZgTHJy8lXnuNI3cODAq67d2tqq1tZWe9/v93/HdwMAALqrHvNXSKWlpYqKirK3xMTEcJcEAABCJKgBxu12S5KampoC2puamuw+t9utkydPBvS3tbXp9OnTAWM6O8f/v8YfKy4uVnNzs719+eWX3/0NAQCAbimoASY5OVlut1vbt2+32/x+v/bu3avMzExJUmZmps6cOaOamhp7zI4dO9TR0aGMjAx7TFVVlS5dumSPqaioUEpKSqcfH0mSy+VSZGRkwAYAAHqmLgeYc+fOyev1yuv1Srr84K7X61VDQ4McDoeee+45/f3f/73+8z//UwcOHNDs2bPl8Xjsv1S69957NWXKFM2dO1cff/yxPvroIy1YsEAzZsyQx+ORJM2cOVNOp1P5+fk6dOiQNmzYoFWrVqmwsDBobxwAAJiryw/x7tu3T5MmTbL3r4SKOXPmaN26dfrbv/1btbS0aN68eTpz5oweeughbd26Vf369bOPWb9+vRYsWKDJkyerV69emj59ul599VW7PyoqStu2bVNBQYHS09MVGxurJUuWBHxXDAAAuH19p++B6c74HhiEC98DAwA3LyzfAwMAAHArEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4fcJdANDTDF28JdwldNnxsrxwlwAAXcIdGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOEEPMEOHDpXD4bhqKygokCRNnDjxqr5nnnkm4BwNDQ3Ky8tT//79FRcXp0WLFqmtrS3YpQIAAEMF/Zt4P/nkE7W3t9v7Bw8e1J/92Z/pL//yL+22uXPnavny5fZ+//797dft7e3Ky8uT2+3W7t271djYqNmzZ6tv3756+eWXg10uAAAwUNADzODBgwP2y8rKNHz4cP3gBz+w2/r37y+3293p8du2bdPhw4dVWVmp+Ph43XfffXrppZdUVFSkkpISOZ3OYJcMAAAME9JnYC5evKh///d/19NPPy2Hw2G3r1+/XrGxsRo1apSKi4t1/vx5u6+6ulqjR49WfHy83ZaTkyO/369Dhw5d81qtra3y+/0BGwAA6JlC+mOOmzZt0pkzZ/TUU0/ZbTNnzlRSUpI8Ho9qa2tVVFSkuro6vf/++5Ikn88XEF4k2fs+n++a1yotLdWyZcuC/yYAAEC3E9IA8+abbyo3N1cej8dumzdvnv169OjRSkhI0OTJk3Xs2DENHz78pq9VXFyswsJCe9/v9ysxMfGmzwcAALqvkAWYL774QpWVlfadlWvJyMiQJB09elTDhw+X2+3Wxx9/HDCmqalJkq753IwkuVwuuVyu71g1AAAwQciegXnrrbcUFxenvLy8bx3n9XolSQkJCZKkzMxMHThwQCdPnrTHVFRUKDIyUqmpqaEqFwAAGCQkd2A6Ojr01ltvac6cOerT55tLHDt2TG+//bamTp2qQYMGqba2VgsXLtSECRM0ZswYSVJ2drZSU1P15JNPqry8XD6fTy+++KIKCgq4wwIAACSFKMBUVlaqoaFBTz/9dEC70+lUZWWlXnnlFbW0tCgxMVHTp0/Xiy++aI/p3bu3Nm/erPnz5yszM1MDBgzQnDlzAr43BgAA3N5CEmCys7NlWdZV7YmJidq1a9d1j09KStJvfvObUJQGAAB6AH4LCQAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABinT7gLABB+QxdvCXcJXXa8LC/cJQAII+7AAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHGCHmBKSkrkcDgCthEjRtj9Fy5cUEFBgQYNGqQ777xT06dPV1NTU8A5GhoalJeXp/79+ysuLk6LFi1SW1tbsEsFAACG6hOKk44cOVKVlZXfXKTPN5dZuHChtmzZovfee09RUVFasGCBHn30UX300UeSpPb2duXl5cntdmv37t1qbGzU7Nmz1bdvX7388suhKBcAABgmJAGmT58+crvdV7U3NzfrzTff1Ntvv60f/vCHkqS33npL9957r/bs2aPvfe972rZtmw4fPqzKykrFx8frvvvu00svvaSioiKVlJTI6XSGomQAAGCQkDwDc+TIEXk8Hg0bNkyzZs1SQ0ODJKmmpkaXLl1SVlaWPXbEiBEaMmSIqqurJUnV1dUaPXq04uPj7TE5OTny+/06dOjQNa/Z2toqv98fsAEAgJ4p6AEmIyND69at09atW7VmzRrV19dr/PjxOnv2rHw+n5xOp6KjowOOiY+Pl8/nkyT5fL6A8HKl/0rftZSWlioqKsreEhMTg/vGAABAtxH0j5Byc3Pt12PGjFFGRoaSkpL0q1/9SnfccUewL2crLi5WYWGhve/3+wkxAAD0UCH/M+ro6Gjdc889Onr0qNxuty5evKgzZ84EjGlqarKfmXG73Vf9VdKV/c6eq7nC5XIpMjIyYAMAAD1TyAPMuXPndOzYMSUkJCg9PV19+/bV9u3b7f66ujo1NDQoMzNTkpSZmakDBw7o5MmT9piKigpFRkYqNTU11OUCAAADBP0jpBdeeEHTpk1TUlKSTpw4oaVLl6p37956/PHHFRUVpfz8fBUWFiomJkaRkZF69tlnlZmZqe9973uSpOzsbKWmpurJJ59UeXm5fD6fXnzxRRUUFMjlcgW7XAAAYKCgB5ivvvpKjz/+uE6dOqXBgwfroYce0p49ezR48GBJ0i9/+Uv16tVL06dPV2trq3JycvTP//zP9vG9e/fW5s2bNX/+fGVmZmrAgAGaM2eOli9fHuxSAQCAoRyWZVnhLiIU/H6/oqKi1NzcHPTnYYYu3hLU8wHouuNleeEuAUAI3Oj/3/wWEgAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTtB/SgAAbgUTvxGbbw8Ggoc7MAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDhBDzClpaV68MEHFRERobi4OD3yyCOqq6sLGDNx4kQ5HI6A7ZlnngkY09DQoLy8PPXv319xcXFatGiR2tragl0uAAAwUJ9gn3DXrl0qKCjQgw8+qLa2Nv385z9Xdna2Dh8+rAEDBtjj5s6dq+XLl9v7/fv3t1+3t7crLy9Pbrdbu3fvVmNjo2bPnq2+ffvq5ZdfDnbJAADAMEEPMFu3bg3YX7duneLi4lRTU6MJEybY7f3795fb7e70HNu2bdPhw4dVWVmp+Ph43XfffXrppZdUVFSkkpISOZ3OYJcNAAAMEvJnYJqbmyVJMTExAe3r169XbGysRo0apeLiYp0/f97uq66u1ujRoxUfH2+35eTkyO/369ChQ6EuGQAAdHNBvwPz/3V0dOi5557T97//fY0aNcpunzlzppKSkuTxeFRbW6uioiLV1dXp/ffflyT5fL6A8CLJ3vf5fJ1eq7W1Va2trfa+3+8P9tsBAADdREgDTEFBgQ4ePKjf/e53Ae3z5s2zX48ePVoJCQmaPHmyjh07puHDh9/UtUpLS7Vs2bLvVC8AADBDyD5CWrBggTZv3qwPP/xQd91117eOzcjIkCQdPXpUkuR2u9XU1BQw5sr+tZ6bKS4uVnNzs719+eWX3/UtAACAbiroAcayLC1YsEAbN27Ujh07lJycfN1jvF6vJCkhIUGSlJmZqQMHDujkyZP2mIqKCkVGRio1NbXTc7hcLkVGRgZsAACgZwr6R0gFBQV6++239cEHHygiIsJ+ZiUqKkp33HGHjh07prfffltTp07VoEGDVFtbq4ULF2rChAkaM2aMJCk7O1upqal68sknVV5eLp/PpxdffFEFBQVyuVzBLhkAABgm6Hdg1qxZo+bmZk2cOFEJCQn2tmHDBkmS0+lUZWWlsrOzNWLECD3//POaPn26fv3rX9vn6N27tzZv3qzevXsrMzNTTzzxhGbPnh3wvTEAAOD2FfQ7MJZlfWt/YmKidu3add3zJCUl6Te/+U2wygIAAD0Iv4UEAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjNMn3AUAwO1i6OIt4S6hy46X5YW7BKBT3IEBAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHH4LSQAwDXx+03orrgDAwAAjEOAAQAAxiHAAAAA4xBgAACAcXiIFwDQo/Dg8e2BOzAAAMA43foOzOrVq7VixQr5fD6lpaXptdde07hx48JdFgAAQcVdo67rtndgNmzYoMLCQi1dulT79+9XWlqacnJydPLkyXCXBgAAwqzbBpiVK1dq7ty5+vGPf6zU1FS9/vrr6t+/v9auXRvu0gAAQJh1y4+QLl68qJqaGhUXF9ttvXr1UlZWlqqrqzs9prW1Va2trfZ+c3OzJMnv9we9vo7W80E/JwAAJgnF/6///7yWZX3ruG4ZYH7/+9+rvb1d8fHxAe3x8fH6/PPPOz2mtLRUy5Ytu6o9MTExJDUCAHA7i3oltOc/e/asoqKirtnfLQPMzSguLlZhYaG939HRodOnT2vQoEFyOBxBu47f71diYqK+/PJLRUZGBu28JmIuLmMeLmMevsFcXMY8XMY8fONG5sKyLJ09e1Yej+dbz9UtA0xsbKx69+6tpqamgPampia53e5Oj3G5XHK5XAFt0dHRoSpRkZGRt/1CvIK5uIx5uIx5+AZzcRnzcBnz8I3rzcW33Xm5ols+xOt0OpWenq7t27fbbR0dHdq+fbsyMzPDWBkAAOgOuuUdGEkqLCzUnDlz9MADD2jcuHF65ZVX1NLSoh//+MfhLg0AAIRZtw0wjz32mP73f/9XS5Yskc/n03333aetW7de9WDvreZyubR06dKrPq66HTEXlzEPlzEP32AuLmMeLmMevhHMuXBY1/s7JQAAgG6mWz4DAwAA8G0IMAAAwDgEGAAAYBwCDAAAMA4BpotWr16toUOHql+/fsrIyNDHH38c7pJuqZKSEjkcjoBtxIgR4S7rlqiqqtK0adPk8XjkcDi0adOmgH7LsrRkyRIlJCTojjvuUFZWlo4cORKeYkPoevPw1FNPXbVGpkyZEp5iQ6i0tFQPPvigIiIiFBcXp0ceeUR1dXUBYy5cuKCCggINGjRId955p6ZPn37VF3Sa7kbmYeLEiVetiWeeeSZMFYfOmjVrNGbMGPtL2jIzM/Vf//Vfdv/tsB6k689DsNYDAaYLNmzYoMLCQi1dulT79+9XWlqacnJydPLkyXCXdkuNHDlSjY2N9va73/0u3CXdEi0tLUpLS9Pq1as77S8vL9err76q119/XXv37tWAAQOUk5OjCxcu3OJKQ+t68yBJU6ZMCVgj77zzzi2s8NbYtWuXCgoKtGfPHlVUVOjSpUvKzs5WS0uLPWbhwoX69a9/rffee0+7du3SiRMn9Oijj4ax6uC7kXmQpLlz5wasifLy8jBVHDp33XWXysrKVFNTo3379umHP/yhHn74YR06dEjS7bEepOvPgxSk9WDhho0bN84qKCiw99vb2y2Px2OVlpaGsapba+nSpVZaWlq4ywg7SdbGjRvt/Y6ODsvtdlsrVqyw286cOWO5XC7rnXfeCUOFt8Yfz4NlWdacOXOshx9+OCz1hNPJkyctSdauXbssy7r879+3b1/rvffes8d89tlnliSruro6XGWG3B/Pg2VZ1g9+8APrb/7mb8JXVBgNHDjQ+pd/+Zfbdj1ccWUeLCt464E7MDfo4sWLqqmpUVZWlt3Wq1cvZWVlqbq6OoyV3XpHjhyRx+PRsGHDNGvWLDU0NIS7pLCrr6+Xz+cLWB9RUVHKyMi47daHJO3cuVNxcXFKSUnR/PnzderUqXCXFHLNzc2SpJiYGElSTU2NLl26FLAmRowYoSFDhvToNfHH83DF+vXrFRsbq1GjRqm4uFjnz58PR3m3THt7u9599121tLQoMzPztl0PfzwPVwRjPXTbb+Ltbn7/+9+rvb39qm8Cjo+P1+effx6mqm69jIwMrVu3TikpKWpsbNSyZcs0fvx4HTx4UBEREeEuL2x8Pp8kdbo+rvTdLqZMmaJHH31UycnJOnbsmH7+858rNzdX1dXV6t27d7jLC4mOjg4999xz+v73v69Ro0ZJurwmnE7nVT8q25PXRGfzIEkzZ85UUlKSPB6PamtrVVRUpLq6Or3//vthrDY0Dhw4oMzMTF24cEF33nmnNm7cqNTUVHm93ttqPVxrHqTgrQcCDLokNzfXfj1mzBhlZGQoKSlJv/rVr5Sfnx/GytBdzJgxw349evRojRkzRsOHD9fOnTs1efLkMFYWOgUFBTp48OBt8zzYtVxrHubNm2e/Hj16tBISEjR58mQdO3ZMw4cPv9VlhlRKSoq8Xq+am5v1H//xH5ozZ4527doV7rJuuWvNQ2pqatDWAx8h3aDY2Fj17t37qifGm5qa5Ha7w1RV+EVHR+uee+7R0aNHw11KWF1ZA6yPqw0bNkyxsbE9do0sWLBAmzdv1ocffqi77rrLbne73bp48aLOnDkTML6nrolrzUNnMjIyJKlHrgmn06m7775b6enpKi0tVVpamlatWnXbrYdrzUNnbnY9EGBukNPpVHp6urZv3263dXR0aPv27QGf691uzp07p2PHjikhISHcpYRVcnKy3G53wPrw+/3au3fvbb0+JOmrr77SqVOnetwasSxLCxYs0MaNG7Vjxw4lJycH9Kenp6tv374Ba6Kurk4NDQ09ak1cbx464/V6JanHrYnOdHR0qLW19bZZD9dyZR46c9Pr4Ts/Bnwbeffddy2Xy2WtW7fOOnz4sDVv3jwrOjra8vl84S7tlnn++eetnTt3WvX19dZHH31kZWVlWbGxsdbJkyfDXVrInT171vr000+tTz/91JJkrVy50vr000+tL774wrIsyyorK7Oio6OtDz74wKqtrbUefvhhKzk52frDH/4Q5sqD69vm4ezZs9YLL7xgVVdXW/X19VZlZaV1//33W3/6p39qXbhwIdylB9X8+fOtqKgoa+fOnVZjY6O9nT9/3h7zzDPPWEOGDLF27Nhh7du3z8rMzLQyMzPDWHXwXW8ejh49ai1fvtzat2+fVV9fb33wwQfWsGHDrAkTJoS58uBbvHixtWvXLqu+vt6qra21Fi9ebDkcDmvbtm2WZd0e68Gyvn0egrkeCDBd9Nprr1lDhgyxnE6nNW7cOGvPnj3hLumWeuyxx6yEhATL6XRaf/Inf2I99thj1tGjR8Nd1i3x4YcfWpKu2ubMmWNZ1uU/pf7FL35hxcfHWy6Xy5o8ebJVV1cX3qJD4Nvm4fz581Z2drY1ePBgq2/fvlZSUpI1d+7cHhnyO5sDSdZbb71lj/nDH/5g/fSnP7UGDhxo9e/f3/rzP/9zq7GxMXxFh8D15qGhocGaMGGCFRMTY7lcLuvuu++2Fi1aZDU3N4e38BB4+umnraSkJMvpdFqDBw+2Jk+ebIcXy7o91oNlffs8BHM9OCzLsrp2zwYAACC8eAYGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOP8H+7QrOMzcjqYAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta 4:**A partir del resultado de la prueba utilizando la funcion de Shapiro, se puede ver que el valor p es inferior a 0,05, por lo que los datos probablemente no sean gaussianos(no siguen una distribucion normal, o se la mayoria de los valores se agrupan alrededor de la media y la frecuencia disminuye a medida que nos alejamos de la media). Esto lo confirma el histograma, que muestra que los datos no son simétricos y tienen una cola más larga en el lado derecho.La concentracion de valores la tenemos entre 0 y 20."
      ],
      "metadata": {
        "id": "F6cESONAlsU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 5\n",
        "\n",
        "Testear si hay correlación significativa entre las variables de años de experiencia y el salario. Hacer un gráfico de dispersión para contrastar con el resultado provisto por el test.\n",
        "\n"
      ],
      "metadata": {
        "id": "aN-QYYwM2oHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "zkj5UrMmBXVq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(pearsonr)\n",
        "help(plt.scatter)"
      ],
      "metadata": {
        "id": "NBsVXYO8BvNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45582dd5-c461-4452-f5db-9d62363473c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function pearsonr in module scipy.stats._stats_py:\n",
            "\n",
            "pearsonr(x, y, *, alternative='two-sided', method=None)\n",
            "    Pearson correlation coefficient and p-value for testing non-correlation.\n",
            "    \n",
            "    The Pearson correlation coefficient [1]_ measures the linear relationship\n",
            "    between two datasets. Like other correlation\n",
            "    coefficients, this one varies between -1 and +1 with 0 implying no\n",
            "    correlation. Correlations of -1 or +1 imply an exact linear relationship.\n",
            "    Positive correlations imply that as x increases, so does y. Negative\n",
            "    correlations imply that as x increases, y decreases.\n",
            "    \n",
            "    This function also performs a test of the null hypothesis that the\n",
            "    distributions underlying the samples are uncorrelated and normally\n",
            "    distributed. (See Kowalski [3]_\n",
            "    for a discussion of the effects of non-normality of the input on the\n",
            "    distribution of the correlation coefficient.)\n",
            "    The p-value roughly indicates the probability of an uncorrelated system\n",
            "    producing datasets that have a Pearson correlation at least as extreme\n",
            "    as the one computed from these datasets.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    x : (N,) array_like\n",
            "        Input array.\n",
            "    y : (N,) array_like\n",
            "        Input array.\n",
            "    alternative : {'two-sided', 'greater', 'less'}, optional\n",
            "        Defines the alternative hypothesis. Default is 'two-sided'.\n",
            "        The following options are available:\n",
            "    \n",
            "        * 'two-sided': the correlation is nonzero\n",
            "        * 'less': the correlation is negative (less than zero)\n",
            "        * 'greater':  the correlation is positive (greater than zero)\n",
            "    \n",
            "        .. versionadded:: 1.9.0\n",
            "    method : ResamplingMethod, optional\n",
            "        Defines the method used to compute the p-value. If `method` is an\n",
            "        instance of `PermutationMethod`/`MonteCarloMethod`, the p-value is\n",
            "        computed using\n",
            "        `scipy.stats.permutation_test`/`scipy.stats.monte_carlo_test` with the\n",
            "        provided configuration options and other appropriate settings.\n",
            "        Otherwise, the p-value is computed as documented in the notes.\n",
            "    \n",
            "        .. versionadded:: 1.11.0\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    result : `~scipy.stats._result_classes.PearsonRResult`\n",
            "        An object with the following attributes:\n",
            "    \n",
            "        statistic : float\n",
            "            Pearson product-moment correlation coefficient.\n",
            "        pvalue : float\n",
            "            The p-value associated with the chosen alternative.\n",
            "    \n",
            "        The object has the following method:\n",
            "    \n",
            "        confidence_interval(confidence_level, method)\n",
            "            This computes the confidence interval of the correlation\n",
            "            coefficient `statistic` for the given confidence level.\n",
            "            The confidence interval is returned in a ``namedtuple`` with\n",
            "            fields `low` and `high`. If `method` is not provided, the\n",
            "            confidence interval is computed using the Fisher transformation\n",
            "            [1]_. If `method` is an instance of `BootstrapMethod`, the\n",
            "            confidence interval is computed using `scipy.stats.bootstrap` with\n",
            "            the provided configuration options and other appropriate settings.\n",
            "            In some cases, confidence limits may be NaN due to a degenerate\n",
            "            resample, and this is typical for very small samples (~6\n",
            "            observations).\n",
            "    \n",
            "    Warns\n",
            "    -----\n",
            "    `~scipy.stats.ConstantInputWarning`\n",
            "        Raised if an input is a constant array.  The correlation coefficient\n",
            "        is not defined in this case, so ``np.nan`` is returned.\n",
            "    \n",
            "    `~scipy.stats.NearConstantInputWarning`\n",
            "        Raised if an input is \"nearly\" constant.  The array ``x`` is considered\n",
            "        nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.\n",
            "        Numerical errors in the calculation ``x - mean(x)`` in this case might\n",
            "        result in an inaccurate calculation of r.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    spearmanr : Spearman rank-order correlation coefficient.\n",
            "    kendalltau : Kendall's tau, a correlation measure for ordinal data.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    The correlation coefficient is calculated as follows:\n",
            "    \n",
            "    .. math::\n",
            "    \n",
            "        r = \\frac{\\sum (x - m_x) (y - m_y)}\n",
            "                 {\\sqrt{\\sum (x - m_x)^2 \\sum (y - m_y)^2}}\n",
            "    \n",
            "    where :math:`m_x` is the mean of the vector x and :math:`m_y` is\n",
            "    the mean of the vector y.\n",
            "    \n",
            "    Under the assumption that x and y are drawn from\n",
            "    independent normal distributions (so the population correlation coefficient\n",
            "    is 0), the probability density function of the sample correlation\n",
            "    coefficient r is ([1]_, [2]_):\n",
            "    \n",
            "    .. math::\n",
            "        f(r) = \\frac{{(1-r^2)}^{n/2-2}}{\\mathrm{B}(\\frac{1}{2},\\frac{n}{2}-1)}\n",
            "    \n",
            "    where n is the number of samples, and B is the beta function.  This\n",
            "    is sometimes referred to as the exact distribution of r.  This is\n",
            "    the distribution that is used in `pearsonr` to compute the p-value when\n",
            "    the `method` parameter is left at its default value (None).\n",
            "    The distribution is a beta distribution on the interval [-1, 1],\n",
            "    with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's\n",
            "    implementation of the beta distribution, the distribution of r is::\n",
            "    \n",
            "        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
            "    \n",
            "    The default p-value returned by `pearsonr` is a two-sided p-value. For a\n",
            "    given sample with correlation coefficient r, the p-value is\n",
            "    the probability that abs(r') of a random sample x' and y' drawn from\n",
            "    the population with zero correlation would be greater than or equal\n",
            "    to abs(r). In terms of the object ``dist`` shown above, the p-value\n",
            "    for a given r and length n can be computed as::\n",
            "    \n",
            "        p = 2*dist.cdf(-abs(r))\n",
            "    \n",
            "    When n is 2, the above continuous distribution is not well-defined.\n",
            "    One can interpret the limit of the beta distribution as the shape\n",
            "    parameters a and b approach a = b = 0 as a discrete distribution with\n",
            "    equal probability masses at r = 1 and r = -1.  More directly, one\n",
            "    can observe that, given the data x = [x1, x2] and y = [y1, y2], and\n",
            "    assuming x1 != x2 and y1 != y2, the only possible values for r are 1\n",
            "    and -1.  Because abs(r') for any sample x' and y' with length 2 will\n",
            "    be 1, the two-sided p-value for a sample of length 2 is always 1.\n",
            "    \n",
            "    For backwards compatibility, the object that is returned also behaves\n",
            "    like a tuple of length two that holds the statistic and the p-value.\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    .. [1] \"Pearson correlation coefficient\", Wikipedia,\n",
            "           https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
            "    .. [2] Student, \"Probable error of a correlation coefficient\",\n",
            "           Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.\n",
            "    .. [3] C. J. Kowalski, \"On the Effects of Non-Normality on the Distribution\n",
            "           of the Sample Product-Moment Correlation Coefficient\"\n",
            "           Journal of the Royal Statistical Society. Series C (Applied\n",
            "           Statistics), Vol. 21, No. 1 (1972), pp. 1-12.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> import numpy as np\n",
            "    >>> from scipy import stats\n",
            "    >>> x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]\n",
            "    >>> res = stats.pearsonr(x, y)\n",
            "    >>> res\n",
            "    PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286)\n",
            "    \n",
            "    To perform an exact permutation version of the test:\n",
            "    \n",
            "    >>> rng = np.random.default_rng(7796654889291491997)\n",
            "    >>> method = stats.PermutationMethod(n_resamples=np.inf, random_state=rng)\n",
            "    >>> stats.pearsonr(x, y, method=method)\n",
            "    PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175)\n",
            "    \n",
            "    To perform the test under the null hypothesis that the data were drawn from\n",
            "    *uniform* distributions:\n",
            "    \n",
            "    >>> method = stats.MonteCarloMethod(rvs=(rng.uniform, rng.uniform))\n",
            "    >>> stats.pearsonr(x, y, method=method)\n",
            "    PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188)\n",
            "    \n",
            "    To produce an asymptotic 90% confidence interval:\n",
            "    \n",
            "    >>> res.confidence_interval(confidence_level=0.9)\n",
            "    ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273)\n",
            "    \n",
            "    And for a bootstrap confidence interval:\n",
            "    \n",
            "    >>> method = stats.BootstrapMethod(method='BCa', random_state=rng)\n",
            "    >>> res.confidence_interval(confidence_level=0.9, method=method)\n",
            "    ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary\n",
            "    \n",
            "    There is a linear dependence between x and y if y = a + b*x + e, where\n",
            "    a,b are constants and e is a random error term, assumed to be independent\n",
            "    of x. For simplicity, assume that x is standard normal, a=0, b=1 and let\n",
            "    e follow a normal distribution with mean zero and standard deviation s>0.\n",
            "    \n",
            "    >>> rng = np.random.default_rng()\n",
            "    >>> s = 0.5\n",
            "    >>> x = stats.norm.rvs(size=500, random_state=rng)\n",
            "    >>> e = stats.norm.rvs(scale=s, size=500, random_state=rng)\n",
            "    >>> y = x + e\n",
            "    >>> stats.pearsonr(x, y).statistic\n",
            "    0.9001942438244763\n",
            "    \n",
            "    This should be close to the exact value given by\n",
            "    \n",
            "    >>> 1/np.sqrt(1 + s**2)\n",
            "    0.8944271909999159\n",
            "    \n",
            "    For s=0.5, we observe a high level of correlation. In general, a large\n",
            "    variance of the noise reduces the correlation, while the correlation\n",
            "    approaches one as the variance of the error goes to zero.\n",
            "    \n",
            "    It is important to keep in mind that no correlation does not imply\n",
            "    independence unless (x, y) is jointly normal. Correlation can even be zero\n",
            "    when there is a very simple dependence structure: if X follows a\n",
            "    standard normal distribution, let y = abs(x). Note that the correlation\n",
            "    between x and y is zero. Indeed, since the expectation of x is zero,\n",
            "    cov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero\n",
            "    by symmetry. The following lines of code illustrate this observation:\n",
            "    \n",
            "    >>> y = np.abs(x)\n",
            "    >>> stats.pearsonr(x, y)\n",
            "    PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743)\n",
            "    \n",
            "    A non-zero correlation coefficient can be misleading. For example, if X has\n",
            "    a standard normal distribution, define y = x if x < 0 and y = 0 otherwise.\n",
            "    A simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797...,\n",
            "    implying a high level of correlation:\n",
            "    \n",
            "    >>> y = np.where(x < 0, x, 0)\n",
            "    >>> stats.pearsonr(x, y)\n",
            "    PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149)\n",
            "    \n",
            "    This is unintuitive since there is no dependence of x and y if x is larger\n",
            "    than zero which happens in about half of the cases if we sample x and y.\n",
            "\n",
            "Help on function scatter in module matplotlib.pyplot:\n",
            "\n",
            "scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, *, edgecolors=None, plotnonfinite=False, data=None, **kwargs)\n",
            "    A scatter plot of *y* vs. *x* with varying marker size and/or color.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    x, y : float or array-like, shape (n, )\n",
            "        The data positions.\n",
            "    \n",
            "    s : float or array-like, shape (n, ), optional\n",
            "        The marker size in points**2 (typographic points are 1/72 in.).\n",
            "        Default is ``rcParams['lines.markersize'] ** 2``.\n",
            "    \n",
            "    c : array-like or list of colors or color, optional\n",
            "        The marker colors. Possible values:\n",
            "    \n",
            "        - A scalar or sequence of n numbers to be mapped to colors using\n",
            "          *cmap* and *norm*.\n",
            "        - A 2D array in which the rows are RGB or RGBA.\n",
            "        - A sequence of colors of length n.\n",
            "        - A single color format string.\n",
            "    \n",
            "        Note that *c* should not be a single numeric RGB or RGBA sequence\n",
            "        because that is indistinguishable from an array of values to be\n",
            "        colormapped. If you want to specify the same RGB or RGBA value for\n",
            "        all points, use a 2D array with a single row.  Otherwise,\n",
            "        value-matching will have precedence in case of a size matching with\n",
            "        *x* and *y*.\n",
            "    \n",
            "        If you wish to specify a single color for all points\n",
            "        prefer the *color* keyword argument.\n",
            "    \n",
            "        Defaults to `None`. In that case the marker color is determined\n",
            "        by the value of *color*, *facecolor* or *facecolors*. In case\n",
            "        those are not specified or `None`, the marker color is determined\n",
            "        by the next color of the ``Axes``' current \"shape and fill\" color\n",
            "        cycle. This cycle defaults to :rc:`axes.prop_cycle`.\n",
            "    \n",
            "    marker : `~.markers.MarkerStyle`, default: :rc:`scatter.marker`\n",
            "        The marker style. *marker* can be either an instance of the class\n",
            "        or the text shorthand for a particular marker.\n",
            "        See :mod:`matplotlib.markers` for more information about marker\n",
            "        styles.\n",
            "    \n",
            "    cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n",
            "        The Colormap instance or registered colormap name used to map scalar data\n",
            "        to colors.\n",
            "    \n",
            "        This parameter is ignored if *c* is RGB(A).\n",
            "    \n",
            "    norm : str or `~matplotlib.colors.Normalize`, optional\n",
            "        The normalization method used to scale scalar data to the [0, 1] range\n",
            "        before mapping to colors using *cmap*. By default, a linear scaling is\n",
            "        used, mapping the lowest value to 0 and the highest to 1.\n",
            "    \n",
            "        If given, this can be one of the following:\n",
            "    \n",
            "        - An instance of `.Normalize` or one of its subclasses\n",
            "          (see :doc:`/tutorials/colors/colormapnorms`).\n",
            "        - A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc.  For a\n",
            "          list of available scales, call `matplotlib.scale.get_scale_names()`.\n",
            "          In that case, a suitable `.Normalize` subclass is dynamically generated\n",
            "          and instantiated.\n",
            "    \n",
            "        This parameter is ignored if *c* is RGB(A).\n",
            "    \n",
            "    vmin, vmax : float, optional\n",
            "        When using scalar data and no explicit *norm*, *vmin* and *vmax* define\n",
            "        the data range that the colormap covers. By default, the colormap covers\n",
            "        the complete value range of the supplied data. It is an error to use\n",
            "        *vmin*/*vmax* when a *norm* instance is given (but using a `str` *norm*\n",
            "        name together with *vmin*/*vmax* is acceptable).\n",
            "    \n",
            "        This parameter is ignored if *c* is RGB(A).\n",
            "    \n",
            "    alpha : float, default: None\n",
            "        The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
            "    \n",
            "    linewidths : float or array-like, default: :rc:`lines.linewidth`\n",
            "        The linewidth of the marker edges. Note: The default *edgecolors*\n",
            "        is 'face'. You may want to change this as well.\n",
            "    \n",
            "    edgecolors : {'face', 'none', *None*} or color or sequence of color, default: :rc:`scatter.edgecolors`\n",
            "        The edge color of the marker. Possible values:\n",
            "    \n",
            "        - 'face': The edge color will always be the same as the face color.\n",
            "        - 'none': No patch boundary will be drawn.\n",
            "        - A color or sequence of colors.\n",
            "    \n",
            "        For non-filled markers, *edgecolors* is ignored. Instead, the color\n",
            "        is determined like with 'face', i.e. from *c*, *colors*, or\n",
            "        *facecolors*.\n",
            "    \n",
            "    plotnonfinite : bool, default: False\n",
            "        Whether to plot points with nonfinite *c* (i.e. ``inf``, ``-inf``\n",
            "        or ``nan``). If ``True`` the points are drawn with the *bad*\n",
            "        colormap color (see `.Colormap.set_bad`).\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    `~matplotlib.collections.PathCollection`\n",
            "    \n",
            "    Other Parameters\n",
            "    ----------------\n",
            "    data : indexable object, optional\n",
            "        If given, the following parameters also accept a string ``s``, which is\n",
            "        interpreted as ``data[s]`` (unless this raises an exception):\n",
            "    \n",
            "        *x*, *y*, *s*, *linewidths*, *edgecolors*, *c*, *facecolor*, *facecolors*, *color*\n",
            "    **kwargs : `~matplotlib.collections.Collection` properties\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    plot : To plot scatter plots when markers are identical in size and\n",
            "        color.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    * The `.plot` function will be faster for scatterplots where markers\n",
            "      don't vary in size or color.\n",
            "    \n",
            "    * Any or all of *x*, *y*, *s*, and *c* may be masked arrays, in which\n",
            "      case all masks will be combined and only unmasked points will be\n",
            "      plotted.\n",
            "    \n",
            "    * Fundamentally, scatter works with 1D arrays; *x*, *y*, *s*, and *c*\n",
            "      may be input as N-D arrays, but within scatter they will be\n",
            "      flattened. The exception is *c*, which will be flattened only if its\n",
            "      size matches the size of *x* and *y*.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.weightstats import zconfint"
      ],
      "metadata": {
        "id": "oTYwHM8rzWBi"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}